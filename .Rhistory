group         = "group")
# Center data just to ignore mean structure
Data <- HolzingerSwineford1939 %>% dplyr::select(x1:x6) %>% scale(x = ., center = T, scale = F) %>% as.data.frame()
Data$group <- HolzingerSwineford1939$school
HS.MM <- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
'
fit.MM <- cfa(HS.MM, data = Data, information = "observed", meanstructure = F, group = "group")
# Get parameter table of step 1
PT.MM <- partable(fit.MM)
# Extract all parameters
est_S1 <- lavInspect(object = fit.MM, what = "est")
cov_S1 <- lapply(est_S1, "[[", "psi")
n_g <- lavInspect(fit.MM, what = "nobs")
p <- Data %>% dplyr::select(x1:x6) %>% ncol()
q <- length(lavNames(fit.MM, type = "lv"))
# Remove the structural parameters of the parameter table
idx.str   <- which(PT.MM$rhs %in% lavNames(fit.MM, type = "lv"))
PT.MM     <- PT.MM[-idx.str, ]
# Fill out MM parameters in the fake table
# First make a full parameter column
PT.MM$par   <- paste0(PT.MM$lhs, PT.MM$op, PT.MM$rhs, ".g", PT.MM$group)
PT.fake$par <- paste0(PT.fake$lhs, PT.fake$op, PT.fake$rhs, ".g", PT.fake$group)
idx.par <- match(PT.MM$par, PT.fake$par) # indices of parameters from PT.MM on PT.fake
PT.fake$ustart[idx.par] <- PT.MM$est
PT.fake$free[is.na(PT.fake$ustart)] <- 1:sum(is.na(PT.fake$ustart))
PT.fake$par <- NULL
# SM
fit.global <- sem(model         = PT.fake,
data          = Data,
information   = "observed",
meanstructure = F,
group         = "group")
# Fit a global SAM ----------------------------------
# MM
HS.MM <- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
'
fit.MM <- cfa(HS.MM, data = Data, information = "observed", meanstructure = F, group = "group")
# Get parameter table of step 1
PT.MM <- partable(fit.MM)
# Extract all parameters
est_S1 <- lavInspect(object = fit.MM, what = "est")
cov_S1 <- lapply(est_S1, "[[", "psi")
n_g <- lavInspect(fit.MM, what = "nobs")
p <- Data %>% dplyr::select(x1:x6) %>% ncol()
q <- length(lavNames(fit.MM, type = "lv"))
# Remove the structural parameters of the parameter table
idx.str   <- which(PT.MM$rhs %in% lavNames(fit.MM, type = "lv"))
PT.MM     <- PT.MM[-idx.str, ]
# Fill out MM parameters in the fake table
# First make a full parameter column
PT.MM$par   <- paste0(PT.MM$lhs, PT.MM$op, PT.MM$rhs, ".g", PT.MM$group)
PT.fake$par <- paste0(PT.fake$lhs, PT.fake$op, PT.fake$rhs, ".g", PT.fake$group)
fit.fake     <- sem(HS.model, data = Data, information = "observed", meanstructure = F, do.fit = F, group = "group")
PT.fake      <- parTable(fit.fake)
PT.fake$se   <- NULL
PT.fake$est  <- NULL
PT.fake$free <- 0
PT.fake$par <- paste0(PT.fake$lhs, PT.fake$op, PT.fake$rhs, ".g", PT.fake$group)
idx.par <- match(PT.MM$par, PT.fake$par) # indices of parameters from PT.MM on PT.fake
PT.fake$ustart[idx.par] <- PT.MM$est
PT.fake$free[is.na(PT.fake$ustart)] <- 1:sum(is.na(PT.fake$ustart))
PT.fake$par <- NULL
# SM
fit.global <- sem(model         = PT.fake,
data          = Data,
information   = "observed",
meanstructure = F,
group         = "group")
summary(fit.global) # Pointwise estimation is correct. SE is underestimated (as expected).
PT.fake
PT.MM$est
PT.fake$start <- NULL
# SM
fit.global <- sem(model         = PT.fake,
data          = Data,
information   = "observed",
meanstructure = F,
group         = "group")
summary(fit.global) # Pointwise estimation is correct. SE is underestimated (as expected).
partable(fit.global)
library(lavaan)
HS.model <- ' visual =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
speed =~ x7 + x8 + x9 '
fit <- cfa(HS.model, data = HolzingerSwineford1939, group = "school",
group.equal = "loadings")
parTable(fit)
fit1 <- cfa(HS.model, data = HolzingerSwineford1939, group = "school",
group.equal = "loadings", ceq.simple = TRUE)
parTable(fit1)
View(parTable(fit))
View(parTable(fit1))
library(lavaan)
HS.model <- ' visual =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
speed =~ x7 + x8 + x9 '
fit <- cfa(HS.model, data = HolzingerSwineford1939, group = "school",
group.equal = "loadings")
fit1 <- cfa(HS.model, data = HolzingerSwineford1939, group = "school",
group.equal = "loadings", ceq.simple = TRUE)
parT <- parTable(fit1)
parT$start <- NULL
parT$est   <- NULL
parT$se    <- NULL
View(parT)
HolzingerSwineford1939
vars <- paste("x", 1:9)
vars <- paste(paste0("x", 1:9), collapse = ",")
cov(HolzingerSwineford1939[HolzingerSwineford1939[, "school"] == x, vars])
unique(HolzingerSwineford1939[, "school"])
Data <- HolzingerSwineford1939
Data <- HolzingerSwineford1939
vars <- paste(paste0("x", 1:9), collapse = ",")
S <- lapply(X = unique(Data[, "school"]), FUN = function(x) {
cov(Data[Data[, "school"] == x, vars])
})
vars
View(Data)
unique(Data[, "school"])
cov(Data[Data[, "school"] == x, vars])
S <- lapply(X = unique(Data[, "school"]),
FUN = function(x) {
cov(Data[Data[, "school"] == x, vars])
}
)
cov(Data[Data[, "school"] == "Pasteur", vars])
Data[Data[, "school"] == "Pasteur", vars]
Data[, "school"] == "Pasteur"
Data[Data[, "school"] == "Pasteur",]
Data[,vars]
Data[,"x1"]
Data[,c("x1", "x2")]
vars <- paste0("x", 1:9)
S <- lapply(X = unique(Data[, "school"]),
FUN = function(x) {
cov(Data[Data[, "school"] == x, vars])
}
)
N_g <- lapply(X = unique(Data[, "school"]),
FUN = function(x) {
nrow(Data[Data[, "school"] == x, vars])
}
)
N_g
fit2 <- cfa(parT, data = HolzingerSwineford1939, sample.cov = S, sample.nobs = N_g, ceq.simple = TRUE)
S <- lapply(X = unique(Data[, "school"]),
FUN = function(x) {
cov(Data[Data[, "school"] == x, vars])
}
)
fit2 <- cfa(parT, sample.cov = S, sample.nobs = N_g, ceq.simple = TRUE)
rm(fit2)
fit2 <- cfa(parT, sample.cov = S, sample.nobs = N_g, ceq.simple = TRUE)
View(fit2)
View(partable(fit2))
View(parT)
fit1 <- cfa(HS.model, data = HolzingerSwineford1939, group = "school",
group.equal = "loadings", ceq.simple = TRUE, meanstructure = F)
parT <- parTable(fit1)
parT$start <- NULL
parT$est   <- NULL
parT$se    <- NULL
Data <- HolzingerSwineford1939
vars <- paste0("x", 1:9)
S <- lapply(X = unique(Data[, "school"]),
FUN = function(x) {
cov(Data[Data[, "school"] == x, vars])
}
)
N_g <- lapply(X = unique(Data[, "school"]),
FUN = function(x) {
nrow(Data[Data[, "school"] == x, vars])
}
)
fit2 <- cfa(parT, sample.cov = S, sample.nobs = N_g, ceq.simple = TRUE)
View(partable(fit2))
fit2 <- cfa(parT, sample.cov = S, sample.nobs = N_g)#, ceq.simple = TRUE)
View(partable(fit2))
rm(fit2)
View(parT)
fit2 <- cfa(parT, sample.cov = S, sample.nobs = N_g)#, ceq.simple = TRUE)
View(partable(fit2))
View(parT)
load("C:/Users/perezalo/OneDrive - Tilburg University/R/Empirical Example/Emotions2/June/Data 06-12.RData")
lavinspect(MMLS.metric.final)
library(lavaan)
lavinspect(MMLS.metric.final)
lavInspect(MMLS.metric.final)
lavInspect(MMLS.metric.final, "est")
lapply(lavInspect(MMLS.metric.final, "est"), "[[", "nu")
View(Dat)
View(Data)
# Metric final
MMLS.metric.final2 <- cfa(model = MMLS, data = Dat, group = "NATION", estimator = "MLM",
std.lv = F, group.equal = "loadings")
lapply(lavInspect(MMLS.metric.final2, "est"), "[[", "nu")
lapply(lavInspect(MMLS.metric.final2, "est"), "[[", "nu")[[1]]
lapply(lavInspect(MMLS.metric.final, "est"), "[[", "nu")[[1]]
g_name
Dat$NATION
group.idx
group.sizes
vars
vars
colnames(Data)
group1 <- Dat[Dat$NATION == "1",]
library(dplyr)
group1 <- group1 %>% select(Q18:Q8) %>% scale(center = T, scale = F)
View(group1)
View(Data)
colMeans(group1)
lapply(lavInspect(MMLS.metric.final2, "est"), "[[", "nu")[[1]]
lapply(lavInspect(MMLS.metric.final, "est"), "[[", "nu")[[1]]
lapply(lavInspect(MMLS.metric.final, "est"), "[[", "nu")[[46]]
lapply(lavInspect(MMLS.metric.final2, "est"), "[[", "nu")[[46]]
lapply(lavInspect(MMLS.metric.final2, "est"), "[[", "lambda")[[46]]
lapply(lavInspect(MMLS.metric.final, "est"), "[[", "lambda")[[46]]
lapply(lavInspect(MMLS.metric.final, "est"), "[[", "lambda")[[44]]
lapply(lavInspect(MMLS.metric.final2, "est"), "[[", "lambda")[[44]]
View(Data)
View(Data)
head(scale(Data[Data$group == "1", -c(1:2)], scale = F))
head(scale(Data[Data$group == 1, -c(1:2)], scale = F))
head(scale(Data[Data$NATION == 1, -c(1:2)], scale = F))
View(Data)
head(scale(Dat[Dat$NATION == 1, -c(1:2)], scale = F))
View(Data)
View(Dat)
View(Data)
View(Dat)
library(misty)
cent <- as.data.frame(Dat) %>% mutate(across(vars, ~misty::center(.x, type="CWC", cluster = group.idx)))
MMLS.metric.final3 <- cfa(model = MMLS, data = cent, group = "NATION", estimator = "MLM",
std.lv = F, group.equal = "loadings")
lapply(lavInspect(MMLS.metric.final, "est"), "[[", "lambda")[[46]]
lapply(lavInspect(MMLS.metric.final2, "est"), "[[", "lambda")[[46]]
lapply(lavInspect(MMLS.metric.final3, "est"), "[[", "lambda")[[46]]
lapply(lavInspect(MMLS.metric.final, "est"), "[[", "lambda")[[46]]; lapply(lavInspect(MMLS.metric.final2, "est"), "[[", "lambda")[[46]]; lapply(lavInspect(MMLS.metric.final3, "est"), "[[", "lambda")[[46]]
lapply(lavInspect(MMLS.metric.final, "est"), "[[", "lambda")[[12]]; lapply(lavInspect(MMLS.metric.final2, "est"), "[[", "lambda")[[12]]; lapply(lavInspect(MMLS.metric.final3, "est"), "[[", "lambda")[[12]]
lapply(lavInspect(MMLS.metric.final, "est"), "[[", "theta")[[12]]; lapply(lavInspect(MMLS.metric.final2, "est"), "[[", "theta")[[12]]; lapply(lavInspect(MMLS.metric.final3, "est"), "[[", "theta")[[12]]
MMfit.final2 <- cfa(model = MM.final, data = Dat, group = "NATION",
group.equal = "loadings", estimator = "MLM",
group.partial = c("NE =~ Q24", "PE =~ Q24",
"NE =~ Q28"),
std.lv = F)
MMfit.final3 <- cfa(model = MM.final, data = cent, group = "NATION",
group.equal = "loadings", estimator = "MLM",
group.partial = c("NE =~ Q24", "PE =~ Q24",
"NE =~ Q28"),
std.lv = F)
lapply(lavInspect(MMfit.final, "est"), "[[", "lambda")[[12]]; lapply(lavInspect(MMfit.final2, "est"), "[[", "lambda")[[12]]; lapply(lavInspect(MMfit.final3, "est"), "[[", "lambda")[[12]]
lapply(lavInspect(MMfit.final, "est"), "[[", "lambda")[[1]]; lapply(lavInspect(MMfit.final2, "est"), "[[", "lambda")[[1]]; lapply(lavInspect(MMfit.final3, "est"), "[[", "lambda")[[1]]
x <- rnorm(100)
b <- x * 5
lm(b ~ x)
y <- b * - 2
lm(cbind(b, y) ~ b + x)
library(lavaan)
x <- rnorm(100)
z <- x * 5
y <- b * - 2
model <- '
# Mediation path
b ~ a * x
y ~ b * z + i * a:b
'
# Fit the model to the data
fit <- sem(model, data = cbind(x,z,y))
model <- '
# Mediation path
z ~ a * x
y ~ b * z + i * a:z
'
# Fit the model to the data
fit <- sem(model, data = cbind(x,z,y))
model <- '
# Mediation path
z ~ a * x
y ~ b * z + i * x:z
'
# Fit the model to the data
fit <- sem(model, data = cbind(x,z,y))
summary(fit)
x <- rnorm(100)
z <- x * 5
y <- z * - 2
model <- '
# Mediation path
z ~ a * x
y ~ b * z + i * x:z
'
# Fit the model to the data
fit <- sem(model, data = cbind(x,z,y))
x <- rnorm(100)
z <- x * 5
y <- z * - 2
lm(cbind(b, y) ~ b + x)
x <- rnorm(100)
z <- x * 5
y <- z * - 2
lm(cbind(b, y) ~ b + x)
lm(cbind(z, y) ~ z + x)
summary(lm(cbind(z, y) ~ z + x))
x <- rnorm(100, 5, 2)
z <- (x * 5) + rnorm(100, 0, 0.05)
y <- (z * - 2) + rnorm(100, 0, 0.05)
summary(lm(cbind(z, y) ~ z + x))
lm(z ~ x)
library(lavaan)
model <- '
# Mediation path
z ~ a * x
y ~ b * z + i * x:z
'
# Fit the model to the data
fit <- sem(model, data = cbind(x,z,y))
summary(fit)
x <- rnorm(100, 5, 2)
z <- (x * 5) + rnorm(100, 0, 0.05)
y <- (z * - 2) + rnorm(100, 0, 0.05)
library(lavaan)
model <- '
# Mediation path
z ~ a * x
y ~ b * z + i * x:z
'
# Fit the model to the data
fit <- sem(model, data = cbind(x,z,y))
summary(fit)
x <- rnorm(100, 5, 2)
z <- (x * 5) + rnorm(100, 0, 0.05)
y <- (z * (- 2 * x)) + rnorm(100, 0, 0.05)
library(lavaan)
model <- '
# Mediation path
z ~ a * x
y ~ b * z + i * x:z
'
# Fit the model to the data
fit <- sem(model, data = cbind(x,z,y))
summary(fit)
x <- rnorm(100, 5, 2)
z <- (x * 5) + rnorm(100, 0, 0.05)
y <- (z * - 2) + (-0.5 * z * x) + rnorm(100, 0, 0.05)
library(lavaan)
model <- '
# Mediation path
z ~ a * x
y ~ b * z + i * x:z
'
# Fit the model to the data
fit <- sem(model, data = cbind(x,z,y))
summary(fit)
x <- rnorm(100, 5, 2)
z <- (x * 5) + rnorm(100, 0)
y <- (z * - 2) + (-0.5 * z * x) + rnorm(100, 0)
library(lavaan)
model <- '
# Mediation path
z ~ a * x
y ~ b * z + i * x:z
'
# Fit the model to the data
fit <- sem(model, data = cbind(x,z,y))
summary(fit)
summary(lm(cbind(z, y) ~ z + x))
x <- rnorm(1000, 5, 2)
z <- (x * 5) + rnorm(1000, 0, 2)
y <- (z * - 2) + (-0.5 * z * x) + rnorm(1000, 0, 2)
library(lavaan)
model <- '
# Mediation path
z ~ a * x
y ~ b * z + i * x:z
'
# Fit the model to the data
fit <- sem(model, data = cbind(x,z,y))
summary(fit)
z <- (x * 5) + runif(1000, -1, 1)
x <- runif(1000, -1, 1)
z <- (x * 5) + runif(1000, -1, 1)
y <- (z * - 2) + (-0.5 * z * x) + runif(1000, -1, 1)
library(lavaan)
model <- '
# Mediation path
z ~ a * x
y ~ b * z + i * x:z
'
# Fit the model to the data
fit <- sem(model, data = cbind(x,z,y))
summary(fit)
summary(lm(cbind(z, y) ~ z + x))
summary(lm(cbind(z, y) ~ z + x + x*z))
model1 <- lm(z ~ x)
model2 <- lm(y ~ z + z:x)
??lm2list
install.packages("lm2list")
install.packages("manymome")
library(manymome)
model1 <- lm(z ~ x)
model2 <- lm(y ~ z + z:x)
lm2list(model1)
lm2list(model1, model2)
summary(lm2list(model1, model2))
summary(fit)
summary(lm2list(model1, model2))
?ginv
MASS::ginv()
MASS::ginv
source("~/GitHub/MMG-SEM/R/SE.R", echo=TRUE)
source("~/GitHub/MMG-SEM/R/MMG-SEM.R", echo=TRUE)
setwd("~/GitHub/ModelSelection_Simulation/")
source("DataGeneration.R")
model <- '
# factor loadings
F1 =~ x1 + x2 + x3 + x4 + x5
F2 =~ z1 + z2 + z3 + z4 + z5
F3 =~ m1 + m2 + m3 + m4 + m5
F4 =~ y1 + y2 + y3 + y4 + y5
# Regression parameters
F4 ~ F1 + F3
F3 ~ F1 + F2
'
S1 <- '
# factor loadings
F1 =~ x1 + x2 + x3 + x4 + x5
F2 =~ z1 + z2 + z3 + z4 + z5
F3 =~ m1 + m2 + m3 + m4 + m5
F4 =~ y1 + y2 + y3 + y4 + y5
'
S2 <- '
# Regression parameters
F4 ~ F1 + F3
F3 ~ F1 + F2
'
set.seed(124*2)
set.seed(124*2)
SimData <- DataGeneration(model     = model,
nclus     = 2,
ngroups   = 12,
reg_coeff = 0.3,
N_g       = 200,
balance   = "bal",
sd        = 0)
library(lavaan)
SimData <- DataGeneration(model     = model,
nclus     = 2,
ngroups   = 12,
reg_coeff = 0.3,
N_g       = 200,
balance   = "bal",
sd        = 0)
library(mmgsem)
system.time(res1 <- ModelSelection(dat = SimData$SimData, step1model = S1, step2model = S2, group = "group",
clusters = c(2, 4), seed = (124*2), nstarts = 10L))
system.time(res1 <- ModelSelection(dat = SimData$SimData, step1model = S1, step2model = S2, group = "group",
clusters = c(1, 6), seed = (124*2), nstarts = 10L))
library(multichull)
install.packages(multichull)
install.packages("multichull")
library(multichull)
res1$Overview
source("~/GitHub/MMG-SEM/R/ModelSelection.R", echo=TRUE)
plot.MMGSEM(res1)
multichull::CHull(data = res1$Overview[, c(4,3)])
res1$Overview[, c(4,3)]
multichull::CHull(data = res1$Overview[, c(4,3)], bound = "upper")
trace(multichull::CHull, browser)
multichull::CHull(data = res1$Overview[, c(4,3)], bound = "upper")
data
data
order
cor(data)[2]
data[, 2] * -1
data
data
UniqueComplex
red_x
I
data[which(data[, 1] == UniqueComplex[teller])
,]
UniqueComplex
tempindex
which.min(tempdata[, 2])
I
tempdata
I
mon_x
mon_x[2:N_remain, 2]
mon_x[1:N_remain - 1, 2])
mon_x[1:N_remain - 1, 2]
mon_x[2:N_remain, 2] - mon_x[1:N_remain - 1, 2]
(mon_x[2:N_remain, 2] - mon_x[1:N_remain - 1, 2]) <
0
mon_x
sum(t == F) > 0
t == F
N_remain
t
t
sum(t == F)
N_remain
untrace(multichull::CHull, browser)
which.max(res1$Overview$Chull)
res1$Overview$Chull
res1$Overview$Chull
res1$Overview$LL
res1$Overview$LL[2] - res1$Overview$LL[3]
