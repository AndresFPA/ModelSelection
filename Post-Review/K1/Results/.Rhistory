lavaan:::computeYHAT(lavmodel, lavmodel@GLIST, fit@SampleStats, ETA = eta)
})
posterior_pred_check[[1]][[1]][,1]
posterior_pred_check[[1]][[1]]
View(SimData)
plot(density(SimData[,"x1"]),
col="red", lwd=4, ylim=c(0,.6))
for(k in 1:rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]) )
}
plot(density(SimData[,"x1"]),
col="red", lwd=4, ylim=c(0,.6))
for(k in 1:rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]) )
}
plot(density(SimData[,"x1"]),
col="red", lwd=4, ylim=c(0,.6))
for(k in 1:rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]), type = "dashed")
}
par(mfrow=c(3,3))
plot(density(SimData[,"x1"]),
col="red", lwd=4, ylim=c(0,.6))
for(k in 1:rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]), lty = "dashed")
}
par(mfrow=c(1,1))
plot(density(SimData[,"x1"]),
col="red", lwd=4, ylim=c(0,.6))
for(k in 1:rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]), lty = "dashed")
}
library(scales)
install.packages("scales")
install.packages("scales")
install.packages("scales")
install.packages("scales")
install.packages("scales")
library(scales)
plot(density(SimData[,"x1"]),
col="red", lwd=4, ylim=c(0,.6))
for(k in 1:rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]), lty = "dashed", alpha = 0.5)
}
par(mfrow=c(1,1))
plot(density(SimData[,"x1"]),
col="red", lwd=4, ylim=c(0,.6))
for(k in 1:rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]), lty = "dashed", alpha = 0.3)
}
?alpha
par(mfrow=c(1,1))
plot(density(SimData[,"x1"]),
col="red", lwd=4, ylim=c(0,.6))
for(k in 1:rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]), lty = "dashed", col = alpha(colour = "gray", alpha = 0.5))
}
for(k in 1:rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]), lty = "dashed", col = alpha(colour = "gray", alpha = 0.2))
}
plot(density(SimData[,"x1"]),
col="red", lwd=4, ylim=c(0,.6))
for(k in 1:rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]), lty = "dashed", col = alpha(colour = "gray", alpha = 0.2))
}
plot(density(SimData[,"x1"]),
col="red", lwd=4, ylim=c(0,.6))
for(k in rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]), lty = "dashed", col = alpha(colour = "gray", alpha = 0.2))
}
plot(density(SimData[,"x1"]),
col="red", lwd=4, ylim=c(0,.6))
for(k in rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,1]), lty = "dashed", col = alpha(colour = "gray", alpha = 0.5))
}
# Plot the real data against the posterior draws for all variables
var_names <- colnames(SimData)
var_names <- colnames(SimData)
par(mfrow=c(2,2))
for(var in 1:20){
plot(density(SimData[,var]), col="red", lwd=4, ylim=c(0,.6), main= paste("Distributions for variable", var_names[var]))
for(k in rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,var]), lty = "dashed", col = alpha(colour = "gray", alpha = 0.5))
}
}
knitr::opts_chunk$set(echo = TRUE)
# Load necessary packages
library(lavaan)
library(blavaan)
library(scales)
knitr::include_graphics('GeneralModel.png')
load('SimData.Rdata')
model <-  '
# factor loadings
F1 =~ z1 + z2 + z3 + z4 + z5
F2 =~ x1 + x2 + x3 + x4 + x5
F3 =~ m1 + m2 + m3 + m4 + m5
F4 =~ y1 + y2 + y3 + y4 + y5
# Regression parameters
F3 ~ prior("normal(0.3, 0.2)")*F2 + prior("normal(0.3, 0.2)")*F1
F4 ~ prior("normal(0, 0.2)")*F2 + prior("normal(0.3, 0.2)")*F3
'
fit <- bsem(model, data = SimData, n.chains = 4, burnin = 100, sample = 500)
# Trace plot to check convergence of the regression parameters
plot(fit, pars = 17:20, plot.type = "trace")
# Rhat to check convergence of all parameters
blavInspect(fit, "rhat")
# Re-fitting
fit2 <- bsem(model, data = SimData, n.chains = 4, burnin = 200, sample = 1000, save.lvs=TRUE) # Save factor scores for later
# Trace plot to check convergence of the regression parameters
plot(fit2, pars = 17:20, plot.type = "trace")
# Rhat to check convergence of all parameters
blavInspect(fit2, "rhat")
# Trace plot to check convergence of the regression parameters
plot(fit2, pars = 17:20, plot.type = "hist")
plot(fit2, pars = 17:20, plot.type = "acf")
# Specify the model
model_default <-  '
# factor loadings
F1 =~ z1 + z2 + z3 + z4 + z5
F2 =~ x1 + x2 + x3 + x4 + x5
F3 =~ m1 + m2 + m3 + m4 + m5
F4 =~ y1 + y2 + y3 + y4 + y5
# Regression parameters
F3 ~ F2 + F1
F4 ~ F2 + F3
'
# Re-fitting
fit_default <- bsem(model_default, data = SimData, n.chains = 4, burnin = 200, sample = 1000)
# Note: Default prior for regression parameters is normal(0,10)
# Specify the model using incorrect priors
model_crazy <-  '
# factor loadings
F1 =~ z1 + z2 + z3 + z4 + z5
F2 =~ x1 + x2 + x3 + x4 + x5
F3 =~ m1 + m2 + m3 + m4 + m5
F4 =~ y1 + y2 + y3 + y4 + y5
# Regression parameters
F3 ~ prior("normal(1, 0.2)")*F2 + prior("normal(1, 0.2)")*F1
F4 ~ prior("normal(2, 0.2)")*F2 + prior("normal(1, 0.2)")*F3
'
# Re-fitting
fit_crazy <- bsem(model_crazy, data = SimData, n.chains = 4, burnin = 200, sample = 1000)
# Extract regression parameters of the three fitted models
betas_fit2        <- blavInspect(blavobject = fit2,        what = "postmean")[17:20] # Original fit
betas_fit_default <- blavInspect(blavobject = fit_default, what = "postmean")[17:20] # Default priors
betas_fit_crazy   <- blavInspect(blavobject = fit_crazy,   what = "postmean")[17:20] # Crazy priors
# Checking absolute bias
round(abs(betas_fit_default - betas_fit2), 4)
round(abs(betas_fit_crazy   - betas_fit2), 4)
# Fit a model that only takes the prior distributions into account
prior_pred_check <- bsem(model, data = SimData, n.chains = 4, burnin = 200, sample = 1000, prisamp = T)
# Check densities of the regression parameters using the prior distributions
plot(prior_pred_check, pars=17:20, plot.type = "dens")
# NOTE: In blavaan, the posterior predictive checks seem to be more oriented to the fit of the whole model (CFI, RMSEA, etc.)
# I tried to do the posterior predictive checks in a similar way to what was presented in the course.
# That is, to compare the distribution of the variables from the data and from the draws generated from the posteriors.
# This code is based on the discussion in the blavaan google group https://groups.google.com/g/blavaan/c/BUIgpeynXSc/m/LxTxgLjTBgAJ
# Check the posterior predicted distributions of the observed variables
psamps  <- do.call("rbind", blavInspect(fit2, 'mcmc'))
lvsamps <- do.call("rbind", blavInspect(fit2, 'lvs'))
# Check the distribution of the observed variables based on the posteriors
posterior_pred_check <- lapply(seq(nrow(psamps)), function(i){
lavmodel <- blavaan:::fill_params(psamps[i,], fit@Model, fit@ParTable)
eta <- blavaan:::fill_eta(lvsamps[i,], fit@Model, fit@ParTable,
fit@SampleStats, fit@Data)
lavaan:::computeYHAT(lavmodel, lavmodel@GLIST, fit@SampleStats, ETA = eta)
})
# Use 50 random posterior draws
rand_samp <- sample(1:nrow(psamps), 50)
# Plot the real data against the posterior draws for all variables
var_names <- colnames(SimData)
par(mfrow=c(2,3))
for(var in 1:20){
plot(density(SimData[,var]), col="red", lwd=4, ylim=c(0,.6), main= paste("Distributions for variable", var_names[var]))
for(k in rand_samp){
lines(density(posterior_pred_check[[k]][[1]][,var]), lty = "dashed", col = alpha(colour = "gray", alpha = 0.5))
}
}
summary(fit2)
summary(fit2, cf = F)
summary(fit2, ci = F)
summary(fit2, ci = T)
update.packages(ask = FALSE, checkBuilt = TRUE)
tinytex::tlmgr_update()
tinytex::reinstall_tinytex()
tinytex::reinstall_tinytex()
tinytex:: install_tinytex()
7000*0.015
60*24
35703 -33982
load("C:/Users/User/OneDrive - Tilburg University/1. Papers/Paper 3/R/24-11-06 Sim Results/Ignored/MM_ResultIgnRow1.Rdata")
load("C:/Users/User/OneDrive - Tilburg University/1. Papers/Paper 3/R/24-11-06 Sim Results/Normal/MM_ResultRow1.Rdata")
colMeans(ResultsRow_MM)
colMeans(ResultsRow_MM.ign)
?lavaan
?lavaan::lavaan
# The Holzinger and Swineford (1939) example
HS.model <- ' visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
speed   =~ x7 + x8 + x9 '
fit <- sem(HS.model, data=HolzingerSwineford1939)
library(lavaan)
# The Holzinger and Swineford (1939) example
HS.model <- ' visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
speed   =~ x7 + x8 + x9 '
fit <- sem(HS.model, data=HolzingerSwineford1939)
fit$cov
fit@SampleStats@cov
library(dplyr)
HolzingerSwineford1939 %>% select(x1:x9) %>% cov()
fit@SampleStats@cov
((HolzingerSwineford1939 %>% select(x1:x9) %>% cov()) * (nrow(HolzingerSwineford1939)-1))/nrow(HolzingerSwineford1939)
fitted(fit)$cov
7200/3
setwd("C:/Users/User/OneDrive - Tilburg University/1. Papers/Paper 2/Methodology (Journal)/Review/Simulation results/ModelSelection_Simulation/Post-Review/All (50+50)/Analyses")
# Load design matrix
# Set wd
# setwd("C:/Users/perezalo/OneDrive - Tilburg University/1. Papers/Paper 2/Methodology (Journal)/Review/Simulation results/ModelSelection_Simulation/Post-Review/All (50+50)/Results")
setwd("C:/Users/User/OneDrive - Tilburg University/1. Papers/Paper 2/Methodology (Journal)/Review/Simulation results/ModelSelection_Simulation/Post-Review/All (50+50)/Results")
load("design.Rdata")
# # Define relevant objects
ncond <- nrow(design) # How many conditions?
K     <- 100 # How many replications?
# Create a matrix to store the maximum scree ratio
results_matrix <- matrix(data = NA,
nrow = (ncond * K),
ncol = 5)
colnames(results_matrix)   <- c("Condition", "Replication", "AIC", "Chull", "True")
results_matrix             <- as.data.frame(results_matrix)
results_matrix$AIC         <- I(vector(mode = "list", length = 2))
results_matrix$Chull       <- I(vector(mode = "list", length = 2))
results_matrix$Chull_first <- NA
results_matrix$Condition   <- rep(x = 1:144, each = 100)
results_matrix$Replication <- rep(x = 1:100, times = 144)
results_matrix$True        <- rep(x = design$nclus, each = 100)
# Load results and input into the matrix
# Prepare new load function
loadRData <- function(fileName){
#loads an RData file, and returns it
load(fileName)
get(ls()[ls() != "fileName"])
}
# setwd("C:/Users/perezalo/OneDrive - Tilburg University/1. Papers/Paper 2/Methodology (Journal)/Review/Simulation results/ModelSelection_Simulation/Post-Review/All (50+50)/Fit")
setwd("C:/Users/User/OneDrive - Tilburg University/1. Papers/Paper 2/Methodology (Journal)/Review/Simulation results/ModelSelection_Simulation/Post-Review/All (50+50)/Fit")
# Get best two results for AIC and Chull
ik <- 0
for(i in 1:ncond){
for(k in 1:100){
# browser()
ik <- ik + 1
file <- list.files(pattern = paste0("^FitRow", i, "Rep", k, "-"), all.files = T)
results_row <- loadRData(file)
AIC_res     <- list(c(which.min(results_row$AIC),
which(results_row$AIC %in% sort(results_row$AIC, decreasing = F)[2]))) # Best two results
Chull_res   <- list(c(which.max(results_row$Chull),
which(results_row$Chull %in% sort(results_row$Chull, decreasing = T)[2]))) # Best two results
results_matrix[ik, "AIC"][[1]]   <- AIC_res
results_matrix[ik, "Chull"][[1]] <- Chull_res
}
}
View(results_matrix)
# CHull alone performance
results_matrix$Chull_per <- NA
# Quick evaluation, do model selection considering the results that repeats the most for both measures
results_matrix$AIC_Chull <- NA
ik <- 0
for(i in 1:ncond){
for(k in 1:100){
ik <- ik + 1
tmp_row  <- c(results_matrix$AIC[ik][[1]], results_matrix$Chull[ik][[1]]) # Extract and put into a vector the results of both measures
freq_row <- table(tmp_row) # frequency table
test     <- sum(max(freq_row) == freq_row) # Which is the winner model?
if(test > 1){ # Is there no clear winner?
results_matrix$AIC_Chull[ik] <- results_matrix$Chull[ik][[1]][1] # Use the first choice from CHull (more consistent)
} else {
results_matrix$AIC_Chull[ik] <- as.numeric(names(which.max(freq_row))) # If there is a clear winner, select it
}
# Just in case also save result CHull and AIC
results_matrix[ik, "Chull_first"] <- results_matrix$Chull[ik][[1]][1]
results_matrix[ik, "AIC_first"] <- results_matrix$AIC[ik][[1]][1]
}
}
# CHull alone performance
results_matrix$Chull_per <- NA
results_matrix$Chull_per <- ifelse(test = results_matrix$True == results_matrix$Chull_first, yes = 0,
no = ifelse(test = results_matrix$True < results_matrix$Chull_first, yes = 1,
no = -1))
# AIC alone performance
results_matrix$AIC_per <- NA
results_matrix$AIC_per <- ifelse(test = results_matrix$True == results_matrix$AIC_first, yes = 0,
no = ifelse(test = results_matrix$True < results_matrix$AIC_first, yes = 1,
no = -1))
# Check individual percentages
sum(results_matrix$AIC_per == 0 & results_matrix$Chull_per == 0)
sum(results_matrix$AIC_per != 0 & results_matrix$Chull_per == 0)
sum(results_matrix$AIC_per == 0 & results_matrix$Chull_per != 0)
# Which models were selected by CHull?
table(results_matrix$Chull_first)
# Which models were selected by CHull?
table(results_matrix$AIC_first)
# 12-11-2024
# Analysis CHull - Simulation K = 1
# Load packages
library(tidyr)
# Define relevant objects
n_cond <- 18 # Number of conditions
K      <- 100 # Number of replications
# Create a matrix to store the maximum scree ratio
results_matrix <- matrix(data = NA,
nrow = (n_cond * K),
ncol = 5)
colnames(results_matrix)   <- c("Condition", "Replication", "Scree", "Selected_K", "Scree_fac")
results_matrix             <- as.data.frame(results_matrix)
results_matrix$Condition   <- rep(x = 1:18, each = 100)
results_matrix$Replication <- rep(x = 1:100, times = 18)
# Load results and input into the matrix
# Prepare new load function
loadRData <- function(fileName){
#loads an RData file, and returns it
load(fileName)
get(ls()[ls() != "fileName"])
}
setwd("C:/Users/perezalo/OneDrive - Tilburg University/1. Papers/Paper 2/Methodology (Journal)/Review/Simulation results/ModelSelection_Simulation/Post-Review/K1/Fit")
setwd("C:/Users/User/OneDrive - Tilburg University/1. Papers/Paper 2/Methodology (Journal)/Review/Simulation results/ModelSelection_Simulation/Post-Review/K1")
#setwd("C:/Users/perezalo/OneDrive - Tilburg University/1. Papers/Paper 2/Methodology (Journal)/Review/Simulation results/ModelSelection_Simulation/Post-Review/K1/Fit")
setwd("C:/Users/User/OneDrive - Tilburg University/1. Papers/Paper 2/Methodology (Journal)/Review/Simulation results/ModelSelection_Simulation/Post-Review/K1/Fit")
ik <- 0
for(i in 1:n_cond){
for(k in 1:K){
ik <- ik + 1
file <- list.files(pattern = paste0("^FitRow", i, "Rep", k, "-"), all.files = T)
results_row <- loadRData(file)
Chull_fac   <- results_row$Overview$Chull_fac
Chull       <- results_row$Overview$Chull
results_matrix[ik, "Scree"]      <- ifelse(test = all(is.na(Chull)), yes = NA, no = max(Chull, na.rm = T))
results_matrix[ik, "Selected_K"] <- ifelse(test = all(is.na(Chull)), yes = NA, no = which.max(Chull))
results_matrix[ik, "Scree_fac"]  <- ifelse(test = all(is.na(Chull_fac)), yes = NA, no = max(Chull_fac, na.rm = T))
}
}
load("C:/Users/User/OneDrive - Tilburg University/1. Papers/Paper 2/Methodology (Journal)/Review/Simulation results/ModelSelection_Simulation/Post-Review/K1/Fit/FitRow1Rep1-1.Rdata")
results$Overview
results$Overview
load("C:/Users/User/OneDrive - Tilburg University/1. Papers/Paper 2/Methodology (Journal)/Review/Simulation results/ModelSelection_Simulation/Post-Review/K1/Fit/FitRow1Rep1-1-DESKTOP-FJALP4V.Rdata")
results$Overview
#setwd("C:/Users/perezalo/OneDrive - Tilburg University/1. Papers/Paper 2/Methodology (Journal)/Review/Simulation results/ModelSelection_Simulation/Post-Review/K1/Fit")
setwd("C:/Users/User/OneDrive - Tilburg University/1. Papers/Paper 2/Methodology (Journal)/Review/Simulation results/ModelSelection_Simulation/Post-Review/K1/Fit")
ik <- 0
for(i in 1:n_cond){
for(k in 1:K){
ik <- ik + 1
file <- list.files(pattern = paste0("^FitRow", i, "Rep", k, "-"), all.files = T)
results_row <- loadRData(file)
Chull_fac   <- results_row$Overview$Chull_fac
Chull       <- results_row$Overview$Chull
results_matrix[ik, "Scree"]      <- ifelse(test = all(is.na(Chull)), yes = NA, no = max(Chull, na.rm = T))
results_matrix[ik, "Selected_K"] <- ifelse(test = all(is.na(Chull)), yes = NA, no = which.max(Chull))
results_matrix[ik, "Scree_fac"]  <- ifelse(test = all(is.na(Chull_fac)), yes = NA, no = max(Chull_fac, na.rm = T))
}
}
mean(x = results_matrix$Scree[is.finite(results_matrix$Scree)])
mean(x = results_matrix$Selected_K[is.finite(results_matrix$Selected_K)])
table(x = results_matrix$Selected_K[is.finite(results_matrix$Selected_K)])
prop.table(x = results_matrix$Selected_K[is.finite(results_matrix$Selected_K)])
table(x = results_matrix$Selected_K[is.finite(results_matrix$Selected_K)])/sum(table(x = results_matrix$Selected_K[is.finite(results_matrix$Selected_K)]))
library(lavaan)
library(qwraps2)
library(fpp3)
library(dplyr)
library(xtable)
library(ggpubr)
library(ggplot2)
library(ggthemes)
# library(Cairo)
# CairoWin()
# Set wd
setwd("C:/Users/perezalo/OneDrive - Tilburg University/1. Papers/Paper 2/Methodology (Journal)/Review/Simulation results/ModelSelection_Simulation/Post-Review/K1/Results")
setwd("C:/Users/User/OneDrive - Tilburg University/1. Papers/Paper 2/Methodology (Journal)/Review/Simulation results/ModelSelection_Simulation/Post-Review/K1")
# Set wd
# setwd("C:/Users/perezalo/OneDrive - Tilburg University/1. Papers/Paper 2/Methodology (Journal)/Review/Simulation results/ModelSelection_Simulation/Post-Review/K1/Results")
setwd("C:/Users/User/OneDrive - Tilburg University/1. Papers/Paper 2/Methodology (Journal)/Review/Simulation results/ModelSelection_Simulation/Post-Review/K1/Results")
# Load empty final results matrix
load("FinalResults.Rdata")
colnames(Results_final)[1:13] <- c("entropyR2", "Chull", "BIC_G", "BIC_N", "AIC", "AIC3", "ICL",
"Chull_fac", "BIC_G_fac", "BIC_N_fac", "AIC_fac", "AIC3_fac", "ICL_fac")
load("design.Rdata")
# Merge datasets
design$Condition <- as.numeric(rownames(design))
Results_final <- merge(x = design, y = Results_final, by = "Condition")
col_order <- c("Condition", "Replication", "nclus", "ngroups", "coeff", "N_g", "balance", "sd",
"entropyR2", "Chull", "BIC_G", "BIC_N", "AIC", "AIC3", "ICL",
"Chull_fac", "BIC_G_fac", "BIC_N_fac", "AIC_fac", "AIC3_fac", "ICL_fac")
Results_final <- Results_final[, col_order]
rm(col_order)
# Fill in the matrix with all results
ncond <- unique(Results_final$Condition) # How many conditions?
K <- length(unique(Results_final$Replication)) # How many replications?
for (i in ncond) {
test <- NA
test <- try(load(paste0("ResultRow", i, ".Rdata")))
if(!c(class(test) == "try-error")){
Results_final[(K*(i-1)+1):(i*K), 9:21] <- ResultsRow
}
}
# REMEMBER THAT THE RESULTS MUST TYPE "FACTOR"
measures <- Results_final %>% dplyr::select(Chull:ICL_fac) %>% as.matrix() %>% as.data.frame()
measures <- lapply(X = measures, FUN = factor, levels = c("-1", "0", "1"), labels = c("-1", "0", "1")) %>% as.data.frame()
Results_final[, 10:21] <- measures
# Check mean results per simulation factor
# Create a function for this
count_results <- function(data, by, type = "count"){
# Extract necessary columns
reduced <- data %>% dplyr::select(Chull:ICL_fac)
#Initialize objects to store
counted        <- vector(mode = "list", length = ncol(reduced))
names(counted) <- colnames(reduced)
final <- c()
# browser()
# Count per column
for(i in 1:ncol(reduced)){
if(length(by) == 1 && by == "total"){
counted[[i]] <- data %>% count(get(colnames(reduced)[i]), .drop = F) %>% filter(!is.na(`get(colnames(reduced)[i])`)) # Count and remove NA
if(type == "relative"){
counted[[i]][, ncol(counted[[i]])] <- round(counted[[i]][, ncol(counted[[i]]), drop = F]/sum(counted[[i]][, ncol(counted[[i]]), drop = F]), 3)
}
# browser()
colnames(counted[[i]]) <- c("result", colnames(reduced)[i]) # change colnames
ifelse(test = i == 1, yes = final <- counted[[i]][, 1, drop = F], no = final <- final) # for the first iteration, keep the group variable and results column
final <- cbind(final, counted[[i]][, ncol(counted[[i]]), drop = F]) # Add the results for each measure
} else {
# browser()
counted[[i]] <- data %>% group_by(across(all_of(by))) %>% count(get(colnames(reduced)[i]), .drop = F) %>% filter(!is.na(`get(colnames(reduced)[i])`)) # count per measure
# browser()
if(type == "relative"){
counted[[i]] <- counted[[i]] %>% group_by(across(all_of(by))) %>% mutate(prop_n = n / sum(n)) %>% select(!n)
# counted[[i]][, ncol(counted[[i]])] <- round(counted[[i]][, ncol(counted[[i]])]/sum(counted[[i]][1:3, ncol(counted[[i]])],), 3)
}
colnames(counted[[i]]) <- c(by, "result", colnames(reduced)[i]) # change colnames
ifelse(test = i == 1, yes = final <- counted[[i]][, c(seq_len(length(by)), (length(by) + 1))], no = final <- final) # for the first iteration, keep the group variable and results column
final <- cbind(final, counted[[i]][, ncol(counted[[i]]), drop = F]) # Add the results for each measure
}
}
return(final)
}
# Pre-check to know if there are NAs
colSums(apply(Results_final, 2, is.na))
# Main effects
count_results(data = Results_final, by = "total", type = "relative")
# HEATMAP
a <- count_results(data = Results_final, by = c("sd", "N_g"), type = "relative") %>% filter(result == "0")
View(a)
a1 <- a %>% dplyr::select(sd, N_g, Chull:ICL) %>% pivot_longer(cols = BIC_G:ICL, names_to = "Measure", values_to = "Proportion")
a1$Proportion <- round(a1$Proportion, 3)
a1$Measure <- factor(a1$Measure, levels = c("BIC_N", "ICL", "BIC_G", "AIC3", "AIC", "Chull"))
plot <- ggplot(data = a1, aes(x = sd, y = Measure)) + facet_grid(~N_g) +
geom_tile(aes(fill = Proportion)) + geom_text(aes(label = Proportion), size = 3.2) +
scale_fill_gradient(low = "yellow", high = "green4") +
scale_x_continuous(sec.axis = sec_axis(~ . , name = "Within-group sample size", breaks = NULL, labels = NULL)) +
labs(x = expression("Within-cluster differences (" * sigma[beta] * ")"),  # Combines text with Greek letter, no space
y = expression("Model Selection measure")) +
scale_y_discrete(labels = c("Chull" = "CHull",
"AIC" = "AIC",
"AIC3" = expression(AIC[3]),
"BIC_G" = expression(BIC[G]),
"ICL" = "ICL",
"BIC_N" = expression(BIC[N])))
plot
count_results(data = Results_final, by = c("nclus"), type = "relative")
count_results(data = Results_final, by = c("nclus"), type = "relative")   %>% select(nclus:ICL, -Chull)
# TABLES
K_res   <- count_results(data = Results_final, by = c("nclus"), type = "relative")   %>% select(nclus:ICL, -Chull)
N_res   <- count_results(data = Results_final, by = c("N_g"), type = "relative")     %>% select(N_g:ICL, -Chull)
G_res   <- count_results(data = Results_final, by = c("ngroups"), type = "relative") %>% select(ngroups:ICL, -Chull)
B_res   <- count_results(data = Results_final, by = c("coeff"), type = "relative")   %>% select(coeff:ICL, -Chull)
Bal_res <- count_results(data = Results_final, by = c("balance"), type = "relative") %>% select(balance:ICL, -Chull)
sd_res  <- count_results(data = Results_final, by = c("sd"), type = "relative")      %>% select(sd:ICL, -Chull)
to_res  <- count_results(data = Results_final, by = "total", type = "relative")      %>% select(result:ICL, -Chull)
K_res   <- K_res %>%
pivot_longer(cols = -c(nclus, result), names_to = "metric", values_to = "value") %>%
pivot_wider(names_from = nclus, values_from = value, names_prefix = "nclus") %>%
relocate(metric) %>% arrange(metric)
N_res   <- N_res %>%
pivot_longer(cols = -c(N_g, result), names_to = "metric", values_to = "value") %>%
pivot_wider(names_from = N_g, values_from = value, names_prefix = "N_g") %>%
relocate(metric) %>% arrange(metric) %>% select(contains("N_g"))
G_res   <- G_res %>%
pivot_longer(cols = -c(ngroups, result), names_to = "metric", values_to = "value") %>%
pivot_wider(names_from = ngroups, values_from = value, names_prefix = "ngroups") %>%
relocate(metric) %>% arrange(metric) %>% select(contains("ngroups"))
B_res   <- B_res %>%
pivot_longer(cols = -c(coeff, result), names_to = "metric", values_to = "value") %>%
pivot_wider(names_from = coeff, values_from = value, names_prefix = "coeff") %>%
relocate(metric) %>% arrange(metric) %>% select(contains("coeff"))
Bal_res <- Bal_res %>%
pivot_longer(cols = -c(balance, result), names_to = "metric", values_to = "value") %>%
pivot_wider(names_from = balance, values_from = value, names_prefix = "balance") %>%
relocate(metric) %>% arrange(metric) %>% select(contains("balance"))
sd_res  <- sd_res %>%
pivot_longer(cols = -c(sd, result), names_to = "metric", values_to = "value") %>%
pivot_wider(names_from = sd, values_from = value, names_prefix = "sd") %>%
relocate(metric) %>% arrange(metric) %>% select(contains("sd"))
to_res  <- to_res %>%
pivot_longer(cols = -c(result), names_to = "metric", values_to = "value") %>%
relocate(metric) %>% arrange(metric) %>% select(value)
final <- cbind(K_res, N_res, G_res, B_res, Bal_res, sd_res, to_res)
# Add totals per column
total_col <- cbind("total", final %>% group_by(result) %>% summarise(across(where(is.numeric), mean, na.rm = TRUE)))
colnames(total_col)[1] <- "metric"; colnames(total_col)[ncol(total_col)] <- "value"
final <- rbind(final, total_col)
final <- final %>% select(metric, result, N_g50, N_g100, N_g200, ngroups24, ngroups48, sd0, sd0.05, sd0.1, value) %>% filter(result != -1)
print(xtable(final), include.rownames=FALSE)
