model <- "f1 =~ x1 + x2 + x3
f2 =~ x4 + x5 + x6
f3 =~ x7 + x8 + x9
f1 ~ f2 + f3"
model.sem  <- sem(model = model, data = ContData, ordered = F, std.lv = F)
library(lavaan)
library(mirt)
library(dplyr)
model.sem  <- sem(model = model, data = ContData, ordered = F, std.lv = F)
x1 <- lambda["x1", "F1"]*FS$F1 + epsilon[, 1]
x2 <- lambda["x2", "F1"]*FS$F1 + epsilon[, 2]
x3 <- lambda["x3", "F1"]*FS$F1 + epsilon[, 3]
x4 <- lambda["x4", "F2"]*FS$F2 + epsilon[, 4]
x5 <- lambda["x5", "F2"]*FS$F2 + epsilon[, 5]
x6 <- lambda["x6", "F2"]*FS$F2 + epsilon[, 6]
x7 <- lambda["x7", "F3"]*FS$F3 + epsilon[, 7]
x8 <- lambda["x8", "F3"]*FS$F3 + epsilon[, 8]
x9 <- lambda["x9", "F3"]*FS$F3 + epsilon[, 9]
ContData <- cbind(x1, x2, x3,
x4, x5, x6,
x7, x8, x9)
##################
# Run continuous model
# Check lavaan cont
model <- "f1 =~ x1 + x2 + x3
f2 =~ x4 + x5 + x6
f3 =~ x7 + x8 + x9
f1 ~ f2 + f3"
model.sem  <- sem(model = model, data = ContData, ordered = F, std.lv = F)
summary(model.sem, rsquare = T)
library(lavaan)
library(mirt)
library(dplyr)
library(MASS)
# Data Generation
# set.seed(5)
# Define relevant variables
N   <- 1000
###################################
# Generate data
cov_F3F2 <- matrix(data = c(1, 0.5,
0.5, 1), nrow = 2, byrow = T)
#################
# Generate factor scores
# F2 and F3
FS <- mvrnorm(n = N, mu = rep(0, 2), Sigma = cov_F3F2, empirical = T)
colnames(FS) <- c("F2", "F3")
FS <- as.data.frame(FS)
# F1
F1 <- (FS$F2*0.3) + (FS$F3*0.3) + rnorm(n = N, mean = 0, sd = 0.05)
# Complete FS
FS <- cbind(F1, FS)
#################
# MM
# Lambda
load <- 0.7
sload <- sqrt(load)
lambda <- matrix(c(1,     0,     0,
sload, 0,     0,
sload, 0,     0,
0,     1,     0,
0,     sload, 0,
0,     sload, 0,
0,     0,     1,
0,     0,     sload,
0,     0,     sload), byrow = T, ncol = 3)
rownames(lambda) <- paste0(rep("x", 9), 1:9)
colnames(lambda) <- colnames(FS)
# Theta
theta <- diag(9)
theta[theta != 0] <- rnorm(9, mean = (1 - load), sd = 0.1)
epsilon <- mvrnorm(n = N, mu = rep(0,9), Sigma = theta)
###################
# Observed data (?) Confusing (latent response?)
x1 <- lambda["x1", "F1"]*FS$F1 + epsilon[, 1]
x2 <- lambda["x2", "F1"]*FS$F1 + epsilon[, 2]
x3 <- lambda["x3", "F1"]*FS$F1 + epsilon[, 3]
x4 <- lambda["x4", "F2"]*FS$F2 + epsilon[, 4]
x5 <- lambda["x5", "F2"]*FS$F2 + epsilon[, 5]
x6 <- lambda["x6", "F2"]*FS$F2 + epsilon[, 6]
x7 <- lambda["x7", "F3"]*FS$F3 + epsilon[, 7]
x8 <- lambda["x8", "F3"]*FS$F3 + epsilon[, 8]
x9 <- lambda["x9", "F3"]*FS$F3 + epsilon[, 9]
ContData <- cbind(x1, x2, x3,
x4, x5, x6,
x7, x8, x9)
##################
# Run continuous model
# Check lavaan cont
model <- "f1 =~ x1 + x2 + x3
f2 =~ x4 + x5 + x6
f3 =~ x7 + x8 + x9
f1 ~ f2 + f3"
model.sem  <- sem(model = model, data = ContData, ordered = F, std.lv = F)
summary(model.sem, rsquare = T)
cor(Data)
library(lavaan)
library(mirt)
library(dplyr)
library(MASS)
# Data Generation
# set.seed(5)
# Define relevant variables
N   <- 1000
###################################
# Generate data
cov_F3F2 <- matrix(data = c(1, 0.5,
0.5, 1), nrow = 2, byrow = T)
#################
# Generate factor scores
# F2 and F3
FS <- mvrnorm(n = N, mu = rep(0, 2), Sigma = cov_F3F2, empirical = T)
colnames(FS) <- c("F2", "F3")
FS <- as.data.frame(FS)
# F1
F1 <- (FS$F2*0.3) + (FS$F3*0.3) + rnorm(n = N, mean = 0, sd = 0.7)
# Complete FS
FS <- cbind(F1, FS)
#################
# MM
# Lambda
load <- 0.7
sload <- sqrt(load)
lambda <- matrix(c(1,     0,     0,
sload, 0,     0,
sload, 0,     0,
0,     1,     0,
0,     sload, 0,
0,     sload, 0,
0,     0,     1,
0,     0,     sload,
0,     0,     sload), byrow = T, ncol = 3)
rownames(lambda) <- paste0(rep("x", 9), 1:9)
colnames(lambda) <- colnames(FS)
# Theta
theta <- diag(9)
theta[theta != 0] <- rnorm(9, mean = (1 - load), sd = 0.1)
epsilon <- mvrnorm(n = N, mu = rep(0,9), Sigma = theta)
###################
# Observed data (?) Confusing (latent response?)
x1 <- lambda["x1", "F1"]*FS$F1 + epsilon[, 1]
x2 <- lambda["x2", "F1"]*FS$F1 + epsilon[, 2]
x3 <- lambda["x3", "F1"]*FS$F1 + epsilon[, 3]
x4 <- lambda["x4", "F2"]*FS$F2 + epsilon[, 4]
x5 <- lambda["x5", "F2"]*FS$F2 + epsilon[, 5]
x6 <- lambda["x6", "F2"]*FS$F2 + epsilon[, 6]
x7 <- lambda["x7", "F3"]*FS$F3 + epsilon[, 7]
x8 <- lambda["x8", "F3"]*FS$F3 + epsilon[, 8]
x9 <- lambda["x9", "F3"]*FS$F3 + epsilon[, 9]
ContData <- cbind(x1, x2, x3,
x4, x5, x6,
x7, x8, x9)
##################
# Run continuous model
# Check lavaan cont
model <- "f1 =~ x1 + x2 + x3
f2 =~ x4 + x5 + x6
f3 =~ x7 + x8 + x9
f1 ~ f2 + f3"
model.sem  <- sem(model = model, data = ContData, ordered = F, std.lv = F)
summary(model.sem, rsquare = T)
cor(Data)
###################################
# Generate data
#################
# Generate factor scores
beta <- matrix(c(0, 0.3, 0.3,
0, 0,   0  ,
0, 0,   0  ), byrow = T, ncol = 3)
psi  <- matrix(c(1, 0,   0,
0, 1,   0.5,
0, 0.5, 1), byrow = T, ncol = 3)
I <- diag(3)
phi <- solve(I - beta) %*% psi %*% solve(t(I - beta))
FS <- as.data.frame(mvrnorm(n = N, mu = rep(0, 3), Sigma = phi, empirical = T)) # These are factor scores
colnames(FS) <- c("F1", "F2", "F3")
library(mirt)
library(dplyr)
library(MASS)
# Data Generation
# set.seed(5)
# Define relevant variables
N   <- 1000
###################################
# Generate data
#################
# Generate factor scores
beta <- matrix(c(0, 0.3, 0.3,
0, 0,   0  ,
0, 0,   0  ), byrow = T, ncol = 3)
psi  <- matrix(c(1, 0,   0,
0, 1,   0.5,
0, 0.5, 1), byrow = T, ncol = 3)
I <- diag(3)
phi <- solve(I - beta) %*% psi %*% solve(t(I - beta))
FS <- as.data.frame(mvrnorm(n = N, mu = rep(0, 3), Sigma = phi, empirical = T)) # These are factor scores
colnames(FS) <- c("F1", "F2", "F3")
#################
# MM
# Lambda
load <- 0.7
sload <- sqrt(load)
lambda <- matrix(c(1,     0,     0,
sload, 0,     0,
sload, 0,     0,
0,     1,     0,
0,     sload, 0,
0,     sload, 0,
0,     0,     1,
0,     0,     sload,
0,     0,     sload), byrow = T, ncol = 3)
rownames(lambda) <- paste0(rep("x", 9), 1:9)
colnames(lambda) <- colnames(FS)
# Theta
theta <- diag(9)
theta[theta != 0] <- rnorm(9, mean = (1 - load), sd = 0.1)
epsilon <- mvrnorm(n = N, mu = rep(0,9), Sigma = theta)
###################
# Observed data (?) Confusing (latent response?)
x1 <- lambda["x1", "F1"]*FS$F1 + epsilon[, 1]
x2 <- lambda["x2", "F1"]*FS$F1 + epsilon[, 2]
x3 <- lambda["x3", "F1"]*FS$F1 + epsilon[, 3]
x4 <- lambda["x4", "F2"]*FS$F2 + epsilon[, 4]
x5 <- lambda["x5", "F2"]*FS$F2 + epsilon[, 5]
x6 <- lambda["x6", "F2"]*FS$F2 + epsilon[, 6]
x7 <- lambda["x7", "F3"]*FS$F3 + epsilon[, 7]
x8 <- lambda["x8", "F3"]*FS$F3 + epsilon[, 8]
x9 <- lambda["x9", "F3"]*FS$F3 + epsilon[, 9]
ContData <- cbind(x1, x2, x3,
x4, x5, x6,
x7, x8, x9)
##################
# Run continuous model
# Check lavaan cont
model <- "f1 =~ x1 + x2 + x3
f2 =~ x4 + x5 + x6
f3 =~ x7 + x8 + x9
f1 ~ f2 + f3"
model.sem  <- sem(model = model, data = ContData, ordered = F, std.lv = F)
summary(model.sem, rsquare = T)
cor(ContData)
thresh1 <- c(-2, 0, 2)
thresh2 <- c(-1, 0, 1)
thresh3 <- c(-1.2, 0.2, 1.2)
thresh4 <- c(-2.3, -0.5, 1)
thresh5 <- c(-1.2, 0.5, 1.7)
thresh6 <- c(-1.3, 0.7, 2.3)
thresh7 <- c(-2.4, -0.3, 0.7)
thresh8 <- c(-1.2, 0.6, 1.8)
thresh9 <- c(-1.4, 0.7, 1.9)
Data <- matrix(data = NA, nrow = 1000, ncol = 9)
Data[, 1] <- as.numeric(cut(ContData[, 1], breaks = c(-Inf, thresh1, Inf)))
Data[, 2] <- as.numeric(cut(ContData[, 1], breaks = c(-Inf, thresh2, Inf)))
Data[, 3] <- as.numeric(cut(ContData[, 1], breaks = c(-Inf, thresh3, Inf)))
Data[, 4] <- as.numeric(cut(ContData[, 2], breaks = c(-Inf, thresh4, Inf)))
Data[, 5] <- as.numeric(cut(ContData[, 2], breaks = c(-Inf, thresh5, Inf)))
Data[, 6] <- as.numeric(cut(ContData[, 2], breaks = c(-Inf, thresh6, Inf)))
Data[, 7] <- as.numeric(cut(ContData[, 3], breaks = c(-Inf, thresh7, Inf)))
Data[, 8] <- as.numeric(cut(ContData[, 3], breaks = c(-Inf, thresh8, Inf)))
Data[, 9] <- as.numeric(cut(ContData[, 3], breaks = c(-Inf, thresh9, Inf)))
View(Data)
colnames(Data) <- paste0(rep("x", 9), 1:9)
cor(Data)
cor(ContData)
lavCor(Data, ordered = T)
Data[, 1] <- as.numeric(cut(ContData[, 1], breaks = c(-Inf, thresh1, Inf)))
Data[, 2] <- as.numeric(cut(ContData[, 2], breaks = c(-Inf, thresh2, Inf)))
Data[, 3] <- as.numeric(cut(ContData[, 3], breaks = c(-Inf, thresh3, Inf)))
Data[, 4] <- as.numeric(cut(ContData[, 4], breaks = c(-Inf, thresh4, Inf)))
Data[, 5] <- as.numeric(cut(ContData[, 5], breaks = c(-Inf, thresh5, Inf)))
Data[, 6] <- as.numeric(cut(ContData[, 6], breaks = c(-Inf, thresh6, Inf)))
Data[, 7] <- as.numeric(cut(ContData[, 7], breaks = c(-Inf, thresh7, Inf)))
Data[, 8] <- as.numeric(cut(ContData[, 8], breaks = c(-Inf, thresh8, Inf)))
Data[, 9] <- as.numeric(cut(ContData[, 9], breaks = c(-Inf, thresh9, Inf)))
colnames(Data) <- paste0(rep("x", 9), 1:9)
cor(Data)
lavCor(Data, ordered = T)
cor(ContData)
# Check lavaan vs mirt
model.sem.cat  <- sem(model = model, data = Data, ordered = T, std.lv = F)
summary(model.sem.cat, rsquare = T)
summary(model.sem, rsquare = T)
lavInspect(model.sem.cat, what = "est")$beta
model.mirt <- mirt(Data,
model = "F1 = 1-3,
F2 = 4-6,
F3 = 7-9",
itemtype = "graded")
fs <- fscores(model.mirt) #, full.scores.SE = T)
View(fs)
lm(F1 ~ F2 + F3, data = as.data.frame(fs))
lm(f1 ~ f2 + f3, data = as.data.frame(predict(model.sem.cat)))
# Lavaan continuous
model.sem.con  <- sem(model = model, data = Data, ordered = F, std.lv = F)
# summary(model.sem.con)
lavInspect(model.sem.con, what = "est")$beta
fs <- fscores(model.mirt, full.scores.SE = T)
fs <- as.data.frame(fs)
fs <- within(fs, {
evar_f1 = SE_F1^1 * (1 - SE_F1)
evar_f2 = SE_F2^1 * (1 - SE_F2)
evar_f3 = SE_F3^1 * (1 - SE_F3)
ld_f1   = 1 - SE_F1
ld_f2   = 1 - SE_F2
ld_f3   = 1 - SE_F3
})
fixed_values <- colMeans(fs)
str.model <- '
eta1 =~ F1
eta2 =~ F2
eta3 =~ F3
eta1 ~ eta2 + eta3
'
str.fit <- cfa(model = str.model, data = fs, std.lv = T, se = "none")
# Adequate par table and fix values
par_table <- parTable(str.fit)
par_table$est <- NULL
par_table$start <- NULL
# Which values are freely estimated?
par_table$free <- 0
par_table$free[par_table$op == "~"] <- 1:sum(par_table$op == "~")
par_table$free[12] <- 3
# Fix values of loadings and error variances
# Loadings
par_table$ustart[1] <- fixed_values["ld_f1"]
par_table$ustart[2] <- fixed_values["ld_f2"]
par_table$ustart[3] <- fixed_values["ld_f3"]
# Error variances
par_table$ustart[6] <- fixed_values["evar_f1"]
par_table$ustart[7] <- fixed_values["evar_f2"]
par_table$ustart[8] <- fixed_values["evar_f3"]
# par_table$free[4] <- 0
# par_table$ustart[4] <- 0.3
# par_table$free[12] <- 0
# par_table$ustart[12] <- 0.5
str.final <- cfa(model = par_table, data = fs, std.lv = T, se = "none")
# summary(str.final)
lavInspect(str.final, what = "est")$beta
library(lavaan)
library(qwraps2)
library(fpp3)
library(dplyr)
library(xtable)
library(ggpubr)
library(ggplot2)
library(ggthemes)
# library(Cairo)
# CairoWin()
# Set wd
setwd("~/GitHub/ModelSelection_Simulation/Results")
# Load empty final results matrix
load("FinalResults.Rdata")
colnames(Results_final)[1:13] <- c("entropyR2", "Chull", "BIC_G", "BIC_N", "AIC", "AIC3", "ICL",
"Chull_fac", "BIC_G_fac", "BIC_N_fac", "AIC_fac", "AIC3_fac", "ICL_fac")
load("design.Rdata")
load("~/GitHub/ModelSelection_Simulation/Results/FinalResCorrectModel.Rdata")
Results_final <- Results_final %>% select(Condition:entropyR2, Chull_fac:ICL_fac)
colnames(Results_final) <- sub(pattern = "_fac", replacement = "", x = colnames(Results_final))
# Fill in the matrix with all results
# ncond <- unique(Results_final$Condition) # How many conditions?
# K <- length(unique(Results_final$Replication)) # How many replications?
# for (i in ncond) {
#   test <- NA
#   test <- try(load(paste0("ResultRow", i, ".Rdata")))
#   if(!c(class(test) == "try-error")){
#     Results_final[(K*(i-1)+1):(i*K), 9:21] <- ResultsRow
#   }
# }
# remove uncomplete entries
# Results_final <- Results_final[!is.na(Results_final$BIC_G), ]
# Turn NAs from Chull into FALSE input (Chull was not able to select any model)
# apply(X = apply(X = Results_final, MARGIN = 2, FUN = is.na), MARGIN = 2, FUN = sum)
# Results_final$`Chull Scree` <- ifelse(test = is.na(Results_final$`Chull Scree`), yes = FALSE, no = Results_final$`Chull Scree`)
# Transform to factor
# changed <- Results_final %>% dplyr::select(Chull:ICL_fac) %>% as.matrix() %>% as.data.frame() %>%
#   mutate(
#     Chull     = recode(Chull, "1" = "0", "TRUE" = "0", "over" = "1", "under" = "-1"),
#     BIC_G     = recode(BIC_G, "1" = "0", "TRUE" = "0", "over" = "1", "under" = "-1"),
#     BIC_N     = recode(BIC_N, "1" = "0", "TRUE" = "0", "over" = "1", "under" = "-1"),
#     AIC       = recode(AIC, "1" = "0", "TRUE" = "0", "over" = "1", "under" = "-1"),
#     AIC3      = recode(AIC3, "1" = "0", "TRUE" = "0", "over" = "1", "under" = "-1"),
#     ICL       = recode(ICL, "1" = "0", "TRUE" = "0", "over" = "1", "under" = "-1"),
#     Chull_fac = recode(Chull_fac, "1" = "0", "TRUE" = "0", "over" = "1", "under" = "-1"),
#     BIC_G_fac = recode(BIC_G_fac, "1" = "0", "TRUE" = "0", "over" = "1", "under" = "-1"),
#     BIC_N_fac = recode(BIC_N_fac, "1" = "0", "TRUE" = "0", "over" = "1", "under" = "-1"),
#     AIC_fac   = recode(AIC_fac, "1" = "0", "TRUE" = "0", "over" = "1", "under" = "-1"),
#     AIC3_fac  = recode(AIC3_fac, "1" = "0", "TRUE" = "0", "over" = "1", "under" = "-1"),
#     ICL_fac   = recode(ICL_fac, "1" = "0", "TRUE" = "0", "over" = "1", "under" = "-1")
#   )
# measures <- Results_final %>% dplyr::select(Chull:ICL_fac) %>% as.matrix() %>% as.data.frame()
#
# measures <- lapply(X = measures, FUN = factor, levels = c("-1", "0", "1"), labels = c("Under", "Correct", "Over")) %>% as.data.frame()
#
# Results_final[, 10:21] <- measures
# Results_final[, "entropyR2"] <- as.numeric(Results_final[, "entropyR2"])
####################################################################################################
############################ TABLES - CLUSTER AND PARAMETER RECOVERY ###############################
####################################################################################################
# Check mean results per simulation factor
# Create a function for this
count_results <- function(data, by, type = "count"){
# Extract necessary columns
reduced <- data %>% dplyr::select(Chull:ICL)
#Initialize objects to store
counted        <- vector(mode = "list", length = ncol(reduced))
names(counted) <- colnames(reduced)
final <- c()
# browser()
# Count per column
for(i in 1:ncol(reduced)){
if(length(by) == 1 && by == "total"){
counted[[i]] <- data %>% count(get(colnames(reduced)[i]), .drop = F) %>% filter(!is.na(`get(colnames(reduced)[i])`)) # Count and remove NA
if(type == "relative"){
counted[[i]][, ncol(counted[[i]])] <- round(counted[[i]][, ncol(counted[[i]]), drop = F]/sum(counted[[i]][, ncol(counted[[i]]), drop = F]), 3)
}
# browser()
colnames(counted[[i]]) <- c("result", colnames(reduced)[i]) # change colnames
ifelse(test = i == 1, yes = final <- counted[[i]][, 1, drop = F], no = final <- final) # for the first iteration, keep the group variable and results column
final <- cbind(final, counted[[i]][, ncol(counted[[i]]), drop = F]) # Add the results for each measure
} else {
# browser()
counted[[i]] <- data %>% group_by(across(all_of(by))) %>% count(get(colnames(reduced)[i]), .drop = F) %>% filter(!is.na(`get(colnames(reduced)[i])`)) # count per measure
# browser()
if(type == "relative"){
counted[[i]][, ncol(counted[[i]])] <- round(counted[[i]][, ncol(counted[[i]])]/sum(counted[[i]][1:3, ncol(counted[[i]])]), 3)
}
colnames(counted[[i]]) <- c(by, "result", colnames(reduced)[i]) # change colnames
ifelse(test = i == 1, yes = final <- counted[[i]][, c(seq_len(length(by)), (length(by) + 1))], no = final <- final) # for the first iteration, keep the group variable and results column
final <- cbind(final, counted[[i]][, ncol(counted[[i]]), drop = F]) # Add the results for each measure
}
}
return(final)
}
# Pre-check to know if there are NAs
colSums(apply(Results_final, 2, is.na))
# Main effects
count_results(data = Results_final, by = "total", type = "relative")
K_res   <- count_results(data = Results_final, by = c("nclus"), type = "relative")
N_res   <- count_results(data = Results_final, by = c("N_g"), type = "relative")
G_res   <- count_results(data = Results_final, by = c("ngroups"), type = "relative")
B_res   <- count_results(data = Results_final, by = c("coeff"), type = "relative")
Bal_res <- count_results(data = Results_final, by = c("balance"), type = "relative")
sd_res  <- count_results(data = Results_final, by = c("sd"), type = "relative")
count_results(data = Results_final, by = c("sd", "N_g"), type = "relative")
mean(Results_final$entropyR2)
View(Results_final %>% group_by(nclus, N_g, ngroups, coeff, balance, sd) %>% summarise(across(entropyR2, mean)))
Results_final %>% group_by(nclus) %>% summarise(across(entropyR2, mean))
Results_final %>% group_by(N_g) %>% summarise(across(entropyR2, mean))
Results_final %>% group_by(ngroups) %>% summarise(across(entropyR2, mean))
Results_final %>% group_by(coeff) %>% summarise(across(entropyR2, mean))
Results_final %>% group_by(balance) %>% summarise(across(entropyR2, mean))
Results_final %>% group_by(sd) %>% summarise(across(entropyR2, mean))
# HEATMAP
a <- count_results(data = Results_final, by = c("sd", "nclus"), type = "relative") %>% filter(result == "Correct")
a1 <- a %>% dplyr::select(sd, nclus, Chull:ICL) %>% pivot_longer(cols = Chull:ICL, names_to = "Measure", values_to = "Proportion")
a1$Measure <- factor(a1$Measure, levels = c("BIC_N", "ICL", "BIC_G", "AIC3", "AIC", "Chull"))
plot <- ggplot(data = a1, aes(x = sd, y = Measure)) + facet_grid(~nclus) +
geom_tile(aes(fill = Proportion)) + geom_text(aes(label = Proportion), size = 3.2) +
scale_fill_gradient(low = "yellow", high = "green4") +
scale_x_continuous(sec.axis = sec_axis(~ . , name = "Number of clusters", breaks = NULL, labels = NULL)) +
labs(x = expression("Within-cluster differences (" * sigma[beta] * ")"),  # Combines text with Greek letter, no space
y = expression("Model Selection measure")) +
scale_y_discrete(labels = c("Chull" = "CHull",
"AIC" = "AIC",
"AIC3" = expression(AIC[3]),
"BIC_G" = expression(BIC[G]),
"ICL" = "ICL",
"BIC_N" = expression(BIC[N])))
# +
# scale_y_discrete(sec.axis = sec_axis(~ . , name = "Number of clusters", breaks = NULL, labels = NULL))
plot
# TABLES
K_res   <- count_results(data = Results_final, by = c("nclus"), type = "relative")   %>% select(nclus:ICL)
N_res   <- count_results(data = Results_final, by = c("N_g"), type = "relative")     %>% select(N_g:ICL)
G_res   <- count_results(data = Results_final, by = c("ngroups"), type = "relative") %>% select(ngroups:ICL)
B_res   <- count_results(data = Results_final, by = c("coeff"), type = "relative")   %>% select(coeff:ICL)
Bal_res <- count_results(data = Results_final, by = c("balance"), type = "relative") %>% select(balance:ICL)
sd_res  <- count_results(data = Results_final, by = c("sd"), type = "relative")      %>% select(sd:ICL)
to_res  <- count_results(data = Results_final, by = "total", type = "relative")      %>% select(result:ICL)
K_res   <- K_res %>%
pivot_longer(cols = -c(nclus, result), names_to = "metric", values_to = "value") %>%
pivot_wider(names_from = nclus, values_from = value, names_prefix = "nclus") %>%
relocate(metric) %>% arrange(metric)
N_res   <- N_res %>%
pivot_longer(cols = -c(N_g, result), names_to = "metric", values_to = "value") %>%
pivot_wider(names_from = N_g, values_from = value, names_prefix = "N_g") %>%
relocate(metric) %>% arrange(metric) %>% select(contains("N_g"))
G_res   <- G_res %>%
pivot_longer(cols = -c(ngroups, result), names_to = "metric", values_to = "value") %>%
pivot_wider(names_from = ngroups, values_from = value, names_prefix = "ngroups") %>%
relocate(metric) %>% arrange(metric) %>% select(contains("ngroups"))
B_res   <- B_res %>%
pivot_longer(cols = -c(coeff, result), names_to = "metric", values_to = "value") %>%
pivot_wider(names_from = coeff, values_from = value, names_prefix = "coeff") %>%
relocate(metric) %>% arrange(metric) %>% select(contains("coeff"))
Bal_res <- Bal_res %>%
pivot_longer(cols = -c(balance, result), names_to = "metric", values_to = "value") %>%
pivot_wider(names_from = balance, values_from = value, names_prefix = "balance") %>%
relocate(metric) %>% arrange(metric) %>% select(contains("balance"))
sd_res  <- sd_res %>%
pivot_longer(cols = -c(sd, result), names_to = "metric", values_to = "value") %>%
pivot_wider(names_from = sd, values_from = value, names_prefix = "sd") %>%
relocate(metric) %>% arrange(metric) %>% select(contains("sd"))
to_res  <- to_res %>%
pivot_longer(cols = -c(result), names_to = "metric", values_to = "value") %>%
relocate(metric) %>% arrange(metric) %>% select(value)
final <- cbind(K_res, N_res, G_res, B_res, Bal_res, sd_res, to_res)
# Add totals per column
total_col <- cbind("total", final %>% group_by(result) %>% summarise(across(where(is.numeric), mean, na.rm = TRUE)))
colnames(total_col)[1] <- "metric"; colnames(total_col)[ncol(total_col)] <- "value"
final <- rbind(final, total_col)
print(xtable(final), include.rownames=FALSE)
