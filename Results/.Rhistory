summary(fit.fake)
# Fit a global SAM ----------------------------------
# MM
HS.MM <- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
'
fit.MM <- cfa(HS.MM, data = Data, information = "observed", meanstructure = F, group = "group")
# Get parameter table of step 1
PT.MM <- partable(fit.MM)
# Extract all parameters
est_S1 <- lavInspect(object = fit.MM, what = "est")
cov_S1 <- lapply(est_S1, "[[", "psi")
n_g <- lavInspect(fit.MM, what = "nobs")
p <- Data %>% dplyr::select(x1:x6) %>% ncol()
q <- length(lavNames(fit.MM, type = "lv"))
# Remove the structural parameters of the parameter table
idx.str   <- which(PT.MM$rhs %in% lavNames(fit.MM, type = "lv"))
PT.MM     <- PT.MM[-idx.str, ]
# Fill out MM parameters in the fake table
# First make a full parameter column
PT.MM$par   <- paste0(PT.MM$lhs, PT.MM$op, PT.MM$rhs, ".g", PT.MM$group)
PT.fake$par <- paste0(PT.fake$lhs, PT.fake$op, PT.fake$rhs, ".g", PT.fake$group)
idx.par <- match(PT.MM$par, PT.fake$par) # indices of parameters from PT.MM on PT.fake
PT.fake$ustart[idx.par] <- PT.MM$est
PT.fake$free[is.na(PT.fake$ustart)] <- 1:sum(is.na(PT.fake$ustart))
PT.fake$par <- NULL
# SM
fit.global <- sem(model         = PT.fake,
data          = Data,
information   = "observed",
meanstructure = F,
group         = "group")
summary(fit.global) # Pointwise estimation is correct. SE is underestimated (as expected).
fit.sem <- sem(HS.model, data = Data,
information = "observed", group = "group"
)
# Fit SAM manually -----------------------------------------------------------------------------------------------------
# Center data to remove mean structure (it simplies stuff)
Data <- HolzingerSwineford1939 %>% dplyr::select(x1:x6) %>% scale(x = ., center = T, scale = F)
# MM
HS.MM <- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
'
fit.MM <- cfa(HS.MM, data = Data, information = "observed")
# Extract all parameters
est_S1 <- lavInspect(object = fit.MM, what = "est")
# lambda_S1 <- est_S1$lambda
# theta_S1  <- est_S1$theta
cov_S1    <- est_S1$psi
# SM
HS.SM <- '
visual ~ textual
'
fit.SM <- sem(HS.SM, sample.cov = cov_S1, sample.nobs = 301, information = "observed")
summary(fit.SM) # Pointwise estimation is correct. SE is underestimated (as expected).
# Extract structural parameters
est_S2 <- lavInspect(object = fit.SM, what = "est")
cov_S2  <- est_S2$psi
# (2) Use numDeriv to replicate all parts of the I matrix --------------------------------------------------------------
p <- ncol(Data)
q <- length(lavNames(fit.MM, type = "lv"))
# First, replicate Hessian of the parameters in Step 1
obj.S1 <- function(x){
lambda <- matrix(data = 0, nrow = p, ncol = q)
lambda[1, 1] <- 1; lambda[4, 2] <- 1
lambda[2:3, 1] <- x[1:2]
lambda[5:6, 2] <- x[3:4]
theta <- matrix(data = 0, nrow = p, ncol = p)
diag(theta) <- x[5:10]
psi <- matrix(data = 0, nrow = q, ncol = q)
psi[1, 1] <- x[11]
psi[2, 2] <- x[12]
psi[2, 1] <- psi[1, 2] <- x[13]
Sigma_new <- lambda %*% psi %*% t(lambda) + theta
LL <- lavaan:::lav_mvnorm_loglik_samplestats(
sample.mean = numeric(6),
sample.nobs = 301, # Use original sample size to get the correct loglikelihood
# sample.nobs = N_gks[g, k],
sample.cov  = (cov(Data) * 300) / 301, # Factor covariance matrix from step 1
Mu          = numeric(2),
Sigma       = Sigma_new # Factor covariance matrix from step 2
)
return(LL)
}
S1par <- coef(fit.MM, type = "free")
H_1 <- numDeriv::hessian(func = obj.S1, x = S1par)
# Second, replicate the Hessian of the parameters of Step 2 (NOT NECESSARY)
obj.S2 <- function(x){
beta <- matrix(data = 0, nrow = q, ncol = q)
beta[1, 2] <- x[1]
psi <- matrix(data = 0, nrow = q, ncol = q)
psi[1, 1] <- x[2]
psi[2, 2] <- x[3]
Sigma_new <- solve(I - beta) %*% psi %*% t(solve(I - beta))
LL <- lavaan:::lav_mvnorm_loglik_samplestats(
sample.mean = numeric(2),
sample.nobs = 301,
sample.cov  = (cov_S1 * 300) / 301,
Mu          = numeric(2),
Sigma       = Sigma_new
)
return(-1 * LL)
}
I <- diag(q)
S2par <- coef(fit.SM, type = "free")
H_2 <- numDeriv::hessian(func = obj.S2, x = S2par)
S2par
# SM
HS.SM <- '
visual ~ textual
textual ~~ textual
'
fit.SM <- sem(HS.SM, sample.cov = cov_S1, sample.nobs = 301, information = "observed")
I <- diag(q)
S2par <- coef(fit.SM, type = "free")
H_2 <- numDeriv::hessian(func = obj.S2, x = S2par)
H_2
# Third, replicate C. Is it possible with numDeriv?
obj.comb <- function(x){
lambda <- matrix(data = 0, nrow = p, ncol = q)
lambda[1, 1] <- 1; lambda[4, 2] <- 1
lambda[2:3, 1] <- x[1:2]
lambda[5:6, 2] <- x[3:4]
theta <- matrix(data = 0, nrow = p, ncol = p)
diag(theta) <- x[5:10]
beta <- matrix(data = 0, nrow = q, ncol = q)
beta[1, 2] <- x[11]
psi <- matrix(data = 0, nrow = q, ncol = q)
psi[1, 1] <- x[12]
psi[2, 2] <- x[13]
Sigma_new <- lambda %*% solve(I - beta) %*% psi %*% t(solve(I - beta)) %*% t(lambda) + theta
LL <- lavaan:::lav_mvnorm_loglik_samplestats(
sample.mean = numeric(6),
sample.nobs = 301,
sample.cov  = (cov(Data) * 300) / 301,
Mu          = numeric(2),
Sigma       = Sigma_new
)
return(LL)
}
HESS <- numDeriv::hessian(func = obj.comb, x = c(S1par[1:10], S2par)) # S2 parameters are different for some reason
I_22
# Extract the individual parts of the matrix
I_11 <- -HESS[1:10, 1:10]
I_22 <- -HESS[11:13, 11:13]
I_21 <- -HESS[11:13, 1:10]
I_22
H2
H_2
1 == 1
# 08-08-2023
# Reproducing the covariance matrix of the parameters in lavaan's SAM (two-step estimation)
library(dplyr)
library(lavaan)
# MG-SEM model for reference -------------------------------------------------------------------------------------------
# Center data just to ignore mean structure
Data <- HolzingerSwineford1939 %>% dplyr::select(x1:x6) %>% scale(x = ., center = T, scale = F) %>% as.data.frame()
Data$group <- HolzingerSwineford1939$school
# Fit a "configural" MG-SEM --------------------------------------------------------------------------------------------
HS.model <- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
visual ~ textual
'
# Fit a "metric" MG-SEM ------------------------------------------------------------------------------------------------
fit.sem.metric <- sem(HS.model, data = Data, information = "observed", group = "group",
meanstructure = F, group.equal = "loadings", ceq.simple = T)
View(partable(fit.sem.metric))
# Fit a "metric" MG-SEM ------------------------------------------------------------------------------------------------
fit.sem.metric <- sem(HS.model, data = Data, information = "observed", group = "group",
meanstructure = F, group.equal = "loadings", ceq.simple = F)
View(partable(fit.sem.metric))
library(lavaan)
library(dplyr)
# Center data just to ignore mean structure
Data <- HolzingerSwineford1939 %>% dplyr::select(x1:x6) %>% scale(x = ., center = T, scale = F) %>% as.data.frame()
Data$group <- HolzingerSwineford1939$school
# Fit SAM manually -----------------------------------------------------------------------------------------------------
# Fit a fake SEM
HS.model <- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
visual ~ textual
'
fit.fake     <- sem(HS.model, data = Data, information = "observed", meanstructure = F, do.fit = F, group = "group")
PT.fake      <- parTable(fit.fake)
PT.fake$se   <- NULL
PT.fake$est  <- NULL
PT.fake$free <- 0
summary(fit.fake)
# Fit a global SAM ----------------------------------
# MM
HS.MM <- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
'
fit.MM <- cfa(HS.MM, data = Data, information = "observed", meanstructure = F, group = "group")
# Get parameter table of step 1
PT.MM <- partable(fit.MM)
# Extract all parameters
est_S1 <- lavInspect(object = fit.MM, what = "est")
cov_S1 <- lapply(est_S1, "[[", "psi")
n_g <- lavInspect(fit.MM, what = "nobs")
p <- Data %>% dplyr::select(x1:x6) %>% ncol()
q <- length(lavNames(fit.MM, type = "lv"))
# Remove the structural parameters of the parameter table
idx.str   <- which(PT.MM$rhs %in% lavNames(fit.MM, type = "lv"))
PT.MM     <- PT.MM[-idx.str, ]
# Fill out MM parameters in the fake table
# First make a full parameter column
PT.MM$par   <- paste0(PT.MM$lhs, PT.MM$op, PT.MM$rhs, ".g", PT.MM$group)
PT.fake$par <- paste0(PT.fake$lhs, PT.fake$op, PT.fake$rhs, ".g", PT.fake$group)
idx.par <- match(PT.MM$par, PT.fake$par) # indices of parameters from PT.MM on PT.fake
PT.fake$ustart[idx.par] <- PT.MM$est
PT.fake$free[is.na(PT.fake$ustart)] <- 1:sum(is.na(PT.fake$ustart))
PT.fake$par <- NULL
PT.fake
PT.MM
fit.fake     <- sem(HS.model, data = Data, information = "observed", meanstructure = F, do.fit = T, group = "group")
partable(fit.fake)
fit.fake     <- sem(HS.model, data = Data, information = "observed", meanstructure = F, do.fit = F, group = "group")
PT.fake      <- parTable(fit.fake)
PT.fake$se   <- NULL
PT.fake$est  <- NULL
PT.fake$free <- 0
summary(fit.fake)
PT.fake
# SM
fit.global <- sem(model         = PT.fake,
data          = Data,
information   = "observed",
meanstructure = F,
group         = "group")
summary(fit.global) # Pointwise estimation is correct. SE is underestimated (as expected).
# SM
fit.global <- sem(model         = PT.fake,
data          = Data,
information   = "observed",
meanstructure = F,
group         = "group")
HS.model <- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
visual ~ textual
'
fit.fake     <- sem(HS.model, data = Data, information = "observed", meanstructure = F, do.fit = F, group = "group")
PT.fake      <- parTable(fit.fake)
PT.fake$se   <- NULL
PT.fake$est  <- NULL
PT.fake$free <- 0
summary(fit.fake)
# Fit a global SAM ----------------------------------
# MM
HS.MM <- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
'
fit.MM <- cfa(HS.MM, data = Data, information = "observed", meanstructure = F, group = "group")
# Get parameter table of step 1
PT.MM <- partable(fit.MM)
# Extract all parameters
est_S1 <- lavInspect(object = fit.MM, what = "est")
cov_S1 <- lapply(est_S1, "[[", "psi")
n_g <- lavInspect(fit.MM, what = "nobs")
p <- Data %>% dplyr::select(x1:x6) %>% ncol()
q <- length(lavNames(fit.MM, type = "lv"))
# Remove the structural parameters of the parameter table
idx.str   <- which(PT.MM$rhs %in% lavNames(fit.MM, type = "lv"))
PT.MM     <- PT.MM[-idx.str, ]
# Fill out MM parameters in the fake table
# First make a full parameter column
PT.MM$par   <- paste0(PT.MM$lhs, PT.MM$op, PT.MM$rhs, ".g", PT.MM$group)
PT.fake$par <- paste0(PT.fake$lhs, PT.fake$op, PT.fake$rhs, ".g", PT.fake$group)
idx.par <- match(PT.MM$par, PT.fake$par) # indices of parameters from PT.MM on PT.fake
PT.fake$ustart[idx.par] <- PT.MM$est
PT.fake$free[is.na(PT.fake$ustart)] <- 1:sum(is.na(PT.fake$ustart))
PT.fake$par <- NULL
# SM
fit.global <- sem(model         = PT.fake,
data          = Data,
information   = "observed",
meanstructure = F,
group         = "group")
# Center data just to ignore mean structure
Data <- HolzingerSwineford1939 %>% dplyr::select(x1:x6) %>% scale(x = ., center = T, scale = F) %>% as.data.frame()
Data$group <- HolzingerSwineford1939$school
HS.MM <- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
'
fit.MM <- cfa(HS.MM, data = Data, information = "observed", meanstructure = F, group = "group")
# Get parameter table of step 1
PT.MM <- partable(fit.MM)
# Extract all parameters
est_S1 <- lavInspect(object = fit.MM, what = "est")
cov_S1 <- lapply(est_S1, "[[", "psi")
n_g <- lavInspect(fit.MM, what = "nobs")
p <- Data %>% dplyr::select(x1:x6) %>% ncol()
q <- length(lavNames(fit.MM, type = "lv"))
# Remove the structural parameters of the parameter table
idx.str   <- which(PT.MM$rhs %in% lavNames(fit.MM, type = "lv"))
PT.MM     <- PT.MM[-idx.str, ]
# Fill out MM parameters in the fake table
# First make a full parameter column
PT.MM$par   <- paste0(PT.MM$lhs, PT.MM$op, PT.MM$rhs, ".g", PT.MM$group)
PT.fake$par <- paste0(PT.fake$lhs, PT.fake$op, PT.fake$rhs, ".g", PT.fake$group)
idx.par <- match(PT.MM$par, PT.fake$par) # indices of parameters from PT.MM on PT.fake
PT.fake$ustart[idx.par] <- PT.MM$est
PT.fake$free[is.na(PT.fake$ustart)] <- 1:sum(is.na(PT.fake$ustart))
PT.fake$par <- NULL
# SM
fit.global <- sem(model         = PT.fake,
data          = Data,
information   = "observed",
meanstructure = F,
group         = "group")
# Fit a global SAM ----------------------------------
# MM
HS.MM <- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
'
fit.MM <- cfa(HS.MM, data = Data, information = "observed", meanstructure = F, group = "group")
# Get parameter table of step 1
PT.MM <- partable(fit.MM)
# Extract all parameters
est_S1 <- lavInspect(object = fit.MM, what = "est")
cov_S1 <- lapply(est_S1, "[[", "psi")
n_g <- lavInspect(fit.MM, what = "nobs")
p <- Data %>% dplyr::select(x1:x6) %>% ncol()
q <- length(lavNames(fit.MM, type = "lv"))
# Remove the structural parameters of the parameter table
idx.str   <- which(PT.MM$rhs %in% lavNames(fit.MM, type = "lv"))
PT.MM     <- PT.MM[-idx.str, ]
# Fill out MM parameters in the fake table
# First make a full parameter column
PT.MM$par   <- paste0(PT.MM$lhs, PT.MM$op, PT.MM$rhs, ".g", PT.MM$group)
PT.fake$par <- paste0(PT.fake$lhs, PT.fake$op, PT.fake$rhs, ".g", PT.fake$group)
fit.fake     <- sem(HS.model, data = Data, information = "observed", meanstructure = F, do.fit = F, group = "group")
PT.fake      <- parTable(fit.fake)
PT.fake$se   <- NULL
PT.fake$est  <- NULL
PT.fake$free <- 0
PT.fake$par <- paste0(PT.fake$lhs, PT.fake$op, PT.fake$rhs, ".g", PT.fake$group)
idx.par <- match(PT.MM$par, PT.fake$par) # indices of parameters from PT.MM on PT.fake
PT.fake$ustart[idx.par] <- PT.MM$est
PT.fake$free[is.na(PT.fake$ustart)] <- 1:sum(is.na(PT.fake$ustart))
PT.fake$par <- NULL
# SM
fit.global <- sem(model         = PT.fake,
data          = Data,
information   = "observed",
meanstructure = F,
group         = "group")
summary(fit.global) # Pointwise estimation is correct. SE is underestimated (as expected).
PT.fake
PT.MM$est
PT.fake$start <- NULL
# SM
fit.global <- sem(model         = PT.fake,
data          = Data,
information   = "observed",
meanstructure = F,
group         = "group")
summary(fit.global) # Pointwise estimation is correct. SE is underestimated (as expected).
partable(fit.global)
library(lavaan)
HS.model <- ' visual =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
speed =~ x7 + x8 + x9 '
fit <- cfa(HS.model, data = HolzingerSwineford1939, group = "school",
group.equal = "loadings")
parTable(fit)
fit1 <- cfa(HS.model, data = HolzingerSwineford1939, group = "school",
group.equal = "loadings", ceq.simple = TRUE)
parTable(fit1)
View(parTable(fit))
View(parTable(fit1))
library(lavaan)
HS.model <- ' visual =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
speed =~ x7 + x8 + x9 '
fit <- cfa(HS.model, data = HolzingerSwineford1939, group = "school",
group.equal = "loadings")
fit1 <- cfa(HS.model, data = HolzingerSwineford1939, group = "school",
group.equal = "loadings", ceq.simple = TRUE)
parT <- parTable(fit1)
parT$start <- NULL
parT$est   <- NULL
parT$se    <- NULL
View(parT)
HolzingerSwineford1939
vars <- paste("x", 1:9)
vars <- paste(paste0("x", 1:9), collapse = ",")
cov(HolzingerSwineford1939[HolzingerSwineford1939[, "school"] == x, vars])
unique(HolzingerSwineford1939[, "school"])
Data <- HolzingerSwineford1939
Data <- HolzingerSwineford1939
vars <- paste(paste0("x", 1:9), collapse = ",")
S <- lapply(X = unique(Data[, "school"]), FUN = function(x) {
cov(Data[Data[, "school"] == x, vars])
})
vars
View(Data)
unique(Data[, "school"])
cov(Data[Data[, "school"] == x, vars])
S <- lapply(X = unique(Data[, "school"]),
FUN = function(x) {
cov(Data[Data[, "school"] == x, vars])
}
)
cov(Data[Data[, "school"] == "Pasteur", vars])
Data[Data[, "school"] == "Pasteur", vars]
Data[, "school"] == "Pasteur"
Data[Data[, "school"] == "Pasteur",]
Data[,vars]
Data[,"x1"]
Data[,c("x1", "x2")]
vars <- paste0("x", 1:9)
S <- lapply(X = unique(Data[, "school"]),
FUN = function(x) {
cov(Data[Data[, "school"] == x, vars])
}
)
N_g <- lapply(X = unique(Data[, "school"]),
FUN = function(x) {
nrow(Data[Data[, "school"] == x, vars])
}
)
N_g
fit2 <- cfa(parT, data = HolzingerSwineford1939, sample.cov = S, sample.nobs = N_g, ceq.simple = TRUE)
S <- lapply(X = unique(Data[, "school"]),
FUN = function(x) {
cov(Data[Data[, "school"] == x, vars])
}
)
fit2 <- cfa(parT, sample.cov = S, sample.nobs = N_g, ceq.simple = TRUE)
rm(fit2)
fit2 <- cfa(parT, sample.cov = S, sample.nobs = N_g, ceq.simple = TRUE)
View(fit2)
View(partable(fit2))
View(parT)
fit1 <- cfa(HS.model, data = HolzingerSwineford1939, group = "school",
group.equal = "loadings", ceq.simple = TRUE, meanstructure = F)
parT <- parTable(fit1)
parT$start <- NULL
parT$est   <- NULL
parT$se    <- NULL
Data <- HolzingerSwineford1939
vars <- paste0("x", 1:9)
S <- lapply(X = unique(Data[, "school"]),
FUN = function(x) {
cov(Data[Data[, "school"] == x, vars])
}
)
N_g <- lapply(X = unique(Data[, "school"]),
FUN = function(x) {
nrow(Data[Data[, "school"] == x, vars])
}
)
fit2 <- cfa(parT, sample.cov = S, sample.nobs = N_g, ceq.simple = TRUE)
View(partable(fit2))
fit2 <- cfa(parT, sample.cov = S, sample.nobs = N_g)#, ceq.simple = TRUE)
View(partable(fit2))
rm(fit2)
View(parT)
fit2 <- cfa(parT, sample.cov = S, sample.nobs = N_g)#, ceq.simple = TRUE)
View(partable(fit2))
View(parT)
library(lavaan)
library(qwraps2)
library(fpp3)
library(dplyr)
library(xtable)
library(ggpubr)
library(ggplot2)
library(ggthemes)
library(Cairo)
# Set wd
setwd("~/GitHub/ModelSelection_Simulation/Results")
# Load empty final results matrix
load("FinalResults.Rdata")
colnames(Results_final)[1:8] <- c("Chull Scree", "BIC_G", "BIC_N", "AIC", "Chull Scree_fac",
"BIC_G_fac", "BIC_N_fac", "AIC_fac")
load("design.Rdata")
# Merge datasets
design$Condition <- as.numeric(rownames(design))
Results_final <- merge(x = design, y = Results_final, by = "Condition")
col_order <- c("Condition", "Replication", "nclus", "ngroups", "coeff", "N_g",
"balance", "reliability", "NonInvSize", "ResRange", "NonInvItems", "NonInvG",
"NonInvType", "Chull Scree", "BIC_G", "BIC_N", "AIC", "Chull Scree_fac",
"BIC_G_fac", "BIC_N_fac", "AIC_fac")
Results_final <- Results_final[, col_order]
rm(col_order)
# Fill in the matrix with all results
ncond <- unique(Results_final$Condition) # How many conditions?
K <- length(unique(Results_final$Replication)) # How many replications?
for (i in ncond) {
test <- NA
test <- try(load(paste0("ResultRow", i, ".Rdata")))
if(!c(class(test) == "try-error")){
Results_final[(K*(i-1)+1):(i*K), 14:21] <- ResultsRow
}
}
# remove uncomplete entries
Results_final <- Results_final[!is.na(Results_final$`Chull Scree`), ]
####################################################################################################
############################ TABLES - CLUSTER AND PARAMETER RECOVERY ###############################
####################################################################################################
Results_final %>% dplyr::select(`Chull Scree`:AIC_fac) %>% apply(MARGIN = 2, FUN = table)
