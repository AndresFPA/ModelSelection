lavInspect(str.final, what = "est")$beta
source("C:/Users/User/OneDrive - Tilburg University/R - Paper 3/OrdinalDataGen.R", echo=TRUE)
sem(model = model, data = Data, ordered = T, std.lv = F)
summary(model.sem.cat, rsquare = T)
View(Data)
apply(Data, 2, histogram)
apply(Data, 2, hist)
hist(Data$x1)
histogram(Data$x1)
apply(Data, 2, histogram)
library(lavaan)
library(mirt)
library(dplyr)
# Data Generation
# set.seed(5)
# Define relevant variables
N   <- 1000
thresh1 <- c(-2, 0, 2)
thresh2 <- c(-2, 0, 2)
thresh3 <- c(-2, 0, 2)
thresh4 <- c(-2, 0, 2)
thresh5 <- c(-2, 0, 2)
thresh6 <- c(-2, 0, 2)
thresh7 <- c(-2, 0, 2)
thresh8 <- c(-2, 0, 2)
thresh9 <- c(-2, 0, 2)
# thresh2 <- c(-1, 0, 1)
# thresh3 <- c(-1.2, 0.2, 1.2)
# thresh4 <- c(-2.3, -0.5, 1)
# thresh5 <- c(-1.2, 0.5, 1.7)
# thresh6 <- c(-1.3, 0.7, 2.3)
# thresh7 <- c(-2.4, -0.3, 0.7)
# thresh8 <- c(-1.2, 0.6, 1.8)
# thresh9 <- c(-1.4, 0.7, 1.9)
# Generate data
# MM
load <- 0.7
sload <- sqrt(load)
lambda <- matrix(c(1,     0,     0,
sload, 0,     0,
sload, 0,     0,
0,     1,     0,
0,     sload, 0,
0,     sload, 0,
0,     0,     1,
0,     0,     sload,
0,     0,     sload), byrow = T, ncol = 3)
theta <- diag(9)
theta[theta != 0] <- rnorm(9, mean = (1 - load), sd = 0.1)
# SM
beta <- matrix(c(0, 0.3, 0.3,
0, 0,   0  ,
0, 0,   0  ), byrow = T, ncol = 3)
psi  <- matrix(c(1, 0,   0,
0, 1,   0.5,
0, 0.5, 1), byrow = T, ncol = 3)
I <- diag(3)
# Observed data
library(MASS)
sigma <- lambda %*% solve(I - beta) %*% psi %*% solve(t(I - beta)) %*% t(lambda) + theta
Data <- as.data.frame(mvrnorm(n = N, mu = rep(0, 9), Sigma = sigma, empirical = T))
colnames(Data) <- paste0(rep("x", 9), 1:9)
# Check lavaan cont
model <- "f1 =~ x1 + x2 + x3
f2 =~ x4 + x5 + x6
f3 =~ x7 + x8 + x9
f1 ~ f2 + f3"
# model.sem  <- sem(model = model, data = Data, ordered = F, std.lv = F)
# summary(model.sem, rsquare = T)
# cor(Data)
# Make categorical
Data[, 1] <- as.numeric(cut(Data[, 1], breaks = c(-Inf, thresh1, Inf)))
Data[, 2] <- as.numeric(cut(Data[, 2], breaks = c(-Inf, thresh2, Inf)))
Data[, 3] <- as.numeric(cut(Data[, 3], breaks = c(-Inf, thresh3, Inf)))
Data[, 4] <- as.numeric(cut(Data[, 4], breaks = c(-Inf, thresh4, Inf)))
Data[, 5] <- as.numeric(cut(Data[, 5], breaks = c(-Inf, thresh5, Inf)))
Data[, 6] <- as.numeric(cut(Data[, 6], breaks = c(-Inf, thresh6, Inf)))
Data[, 7] <- as.numeric(cut(Data[, 7], breaks = c(-Inf, thresh7, Inf)))
Data[, 8] <- as.numeric(cut(Data[, 8], breaks = c(-Inf, thresh8, Inf)))
Data[, 9] <- as.numeric(cut(Data[, 9], breaks = c(-Inf, thresh9, Inf)))
# cor(Data)
# lavCor(Data, ordered = T)
# Check lavaan vs mirt
model.sem.cat  <- sem(model = model, data = Data, ordered = T, std.lv = F)
# summary(model.sem.cat, rsquare = T)
lavInspect(model.sem.cat, what = "est")$beta
model.mirt <- mirt(Data,
model = "F1 = 1-3,
F2 = 4-6,
F3 = 7-9",
itemtype = "graded")
# coef(model.mirt)
# summary(model.mirt)
fs <- fscores(model.mirt) #, full.scores.SE = T)
lm(F1 ~ F2 + F3, data = as.data.frame(fs))
lm(f1 ~ f2 + f3, data = as.data.frame(predict(model.sem.cat)))
predict(model.sem.cat)
# Lavaan continuous
model.sem.con  <- sem(model = model, data = Data, ordered = F, std.lv = F)
# summary(model.sem.con)
lavInspect(model.sem.con, what = "est")$beta
# cov(fs)
#
# str.model <- '
#   F1 ~ F2 + F3
# '
#
# str.fit <- sem(model = str.model, sample.cov = cov(fs), sample.nobs = 500, sample.mean = colMeans(fs))
# summary(str.fit)
# SINGLE INDICATOR
fs <- fscores(model.mirt, full.scores.SE = T)
fs <- as.data.frame(fs)
fs <- within(fs, {
evar_f1 = SE_F1^1 * (1 - SE_F1)
evar_f2 = SE_F2^1 * (1 - SE_F2)
evar_f3 = SE_F3^1 * (1 - SE_F3)
ld_f1   = 1 - SE_F1
ld_f2   = 1 - SE_F2
ld_f3   = 1 - SE_F3
})
fixed_values <- colMeans(fs)
str.model <- '
eta1 =~ F1
eta2 =~ F2
eta3 =~ F3
eta1 ~ eta2 + eta3
'
str.fit <- cfa(model = str.model, data = fs, std.lv = T, se = "none")
# Adequate par table and fix values
par_table <- parTable(str.fit)
par_table$est <- NULL
par_table$start <- NULL
# Which values are freely estimated?
par_table$free <- 0
par_table$free[par_table$op == "~"] <- 1:sum(par_table$op == "~")
par_table$free[12] <- 3
# Fix values of loadings and error variances
# Loadings
par_table$ustart[1] <- fixed_values["ld_f1"]
par_table$ustart[2] <- fixed_values["ld_f2"]
par_table$ustart[3] <- fixed_values["ld_f3"]
# Error variances
par_table$ustart[6] <- fixed_values["evar_f1"]
par_table$ustart[7] <- fixed_values["evar_f2"]
par_table$ustart[8] <- fixed_values["evar_f3"]
# par_table$free[4] <- 0
# par_table$ustart[4] <- 0.3
# par_table$free[12] <- 0
# par_table$ustart[12] <- 0.5
str.final <- cfa(model = par_table, data = fs, std.lv = T, se = "none")
# summary(str.final)
lavInspect(str.final, what = "est")$beta
library(lavaan)
library(mirt)
library(dplyr)
# Data Generation
# set.seed(5)
# Define relevant variables
N   <- 1000
thresh1 <- c(-1.2, 0.2, 1.2)
thresh2 <- c(-1.2, 0.2, 1.2)
thresh3 <- c(-1.2, 0.2, 1.2)
thresh4 <- c(-1.2, 0.2, 1.2)
thresh5 <- c(-1.2, 0.2, 1.2)
thresh6 <- c(-1.2, 0.2, 1.2)
thresh7 <- c(-1.2, 0.2, 1.2)
thresh8 <- c(-1.2, 0.2, 1.2)
thresh9 <- c(-1.2, 0.2, 1.2)
# thresh1 <- c(-2, 0, 2)
# thresh2 <- c(-1, 0, 1)
# thresh3 <- c(-1.2, 0.2, 1.2)
# thresh4 <- c(-2.3, -0.5, 1)
# thresh5 <- c(-1.2, 0.5, 1.7)
# thresh6 <- c(-1.3, 0.7, 2.3)
# thresh7 <- c(-2.4, -0.3, 0.7)
# thresh8 <- c(-1.2, 0.6, 1.8)
# thresh9 <- c(-1.4, 0.7, 1.9)
# Generate data
# MM
load <- 0.7
sload <- sqrt(load)
lambda <- matrix(c(1,     0,     0,
sload, 0,     0,
sload, 0,     0,
0,     1,     0,
0,     sload, 0,
0,     sload, 0,
0,     0,     1,
0,     0,     sload,
0,     0,     sload), byrow = T, ncol = 3)
theta <- diag(9)
theta[theta != 0] <- rnorm(9, mean = (1 - load), sd = 0.1)
# SM
beta <- matrix(c(0, 0.3, 0.3,
0, 0,   0  ,
0, 0,   0  ), byrow = T, ncol = 3)
psi  <- matrix(c(1, 0,   0,
0, 1,   0.5,
0, 0.5, 1), byrow = T, ncol = 3)
I <- diag(3)
# Observed data
library(MASS)
sigma <- lambda %*% solve(I - beta) %*% psi %*% solve(t(I - beta)) %*% t(lambda) + theta
Data <- as.data.frame(mvrnorm(n = N, mu = rep(0, 9), Sigma = sigma, empirical = T))
colnames(Data) <- paste0(rep("x", 9), 1:9)
# Check lavaan cont
model <- "f1 =~ x1 + x2 + x3
f2 =~ x4 + x5 + x6
f3 =~ x7 + x8 + x9
f1 ~ f2 + f3"
# model.sem  <- sem(model = model, data = Data, ordered = F, std.lv = F)
# summary(model.sem, rsquare = T)
# cor(Data)
# Make categorical
Data[, 1] <- as.numeric(cut(Data[, 1], breaks = c(-Inf, thresh1, Inf)))
Data[, 2] <- as.numeric(cut(Data[, 2], breaks = c(-Inf, thresh2, Inf)))
Data[, 3] <- as.numeric(cut(Data[, 3], breaks = c(-Inf, thresh3, Inf)))
Data[, 4] <- as.numeric(cut(Data[, 4], breaks = c(-Inf, thresh4, Inf)))
Data[, 5] <- as.numeric(cut(Data[, 5], breaks = c(-Inf, thresh5, Inf)))
Data[, 6] <- as.numeric(cut(Data[, 6], breaks = c(-Inf, thresh6, Inf)))
Data[, 7] <- as.numeric(cut(Data[, 7], breaks = c(-Inf, thresh7, Inf)))
Data[, 8] <- as.numeric(cut(Data[, 8], breaks = c(-Inf, thresh8, Inf)))
Data[, 9] <- as.numeric(cut(Data[, 9], breaks = c(-Inf, thresh9, Inf)))
# cor(Data)
# lavCor(Data, ordered = T)
# Check lavaan vs mirt
model.sem.cat  <- sem(model = model, data = Data, ordered = T, std.lv = F)
# summary(model.sem.cat, rsquare = T)
lavInspect(model.sem.cat, what = "est")$beta
model.mirt <- mirt(Data,
model = "F1 = 1-3,
F2 = 4-6,
F3 = 7-9",
itemtype = "graded")
# coef(model.mirt)
# summary(model.mirt)
fs <- fscores(model.mirt) #, full.scores.SE = T)
lm(F1 ~ F2 + F3, data = as.data.frame(fs))
lm(f1 ~ f2 + f3, data = as.data.frame(predict(model.sem.cat)))
# Lavaan continuous
model.sem.con  <- sem(model = model, data = Data, ordered = F, std.lv = F)
# summary(model.sem.con)
lavInspect(model.sem.con, what = "est")$beta
# cov(fs)
#
# str.model <- '
#   F1 ~ F2 + F3
# '
#
# str.fit <- sem(model = str.model, sample.cov = cov(fs), sample.nobs = 500, sample.mean = colMeans(fs))
# summary(str.fit)
# SINGLE INDICATOR
fs <- fscores(model.mirt, full.scores.SE = T)
fs <- as.data.frame(fs)
fs <- within(fs, {
evar_f1 = SE_F1^1 * (1 - SE_F1)
evar_f2 = SE_F2^1 * (1 - SE_F2)
evar_f3 = SE_F3^1 * (1 - SE_F3)
ld_f1   = 1 - SE_F1
ld_f2   = 1 - SE_F2
ld_f3   = 1 - SE_F3
})
fixed_values <- colMeans(fs)
str.model <- '
eta1 =~ F1
eta2 =~ F2
eta3 =~ F3
eta1 ~ eta2 + eta3
'
str.fit <- cfa(model = str.model, data = fs, std.lv = T, se = "none")
# Adequate par table and fix values
par_table <- parTable(str.fit)
par_table$est <- NULL
par_table$start <- NULL
# Which values are freely estimated?
par_table$free <- 0
par_table$free[par_table$op == "~"] <- 1:sum(par_table$op == "~")
par_table$free[12] <- 3
# Fix values of loadings and error variances
# Loadings
par_table$ustart[1] <- fixed_values["ld_f1"]
par_table$ustart[2] <- fixed_values["ld_f2"]
par_table$ustart[3] <- fixed_values["ld_f3"]
# Error variances
par_table$ustart[6] <- fixed_values["evar_f1"]
par_table$ustart[7] <- fixed_values["evar_f2"]
par_table$ustart[8] <- fixed_values["evar_f3"]
# par_table$free[4] <- 0
# par_table$ustart[4] <- 0.3
# par_table$free[12] <- 0
# par_table$ustart[12] <- 0.5
str.final <- cfa(model = par_table, data = fs, std.lv = T, se = "none")
# summary(str.final)
lavInspect(str.final, what = "est")$beta
185/214
196/243
library(lavaan)
library(qwraps2)
library(fpp3)
library(dplyr)
library(xtable)
library(ggpubr)
library(ggplot2)
library(ggthemes)
# library(Cairo)
# CairoWin()
# Set wd
setwd("~/GitHub/ModelSelection_Simulation/Results")
# Load empty final results matrix
load("FinalResults.Rdata")
colnames(Results_final)[1:13] <- c("entropyR2", "Chull", "BIC_G", "BIC_N", "AIC", "AIC3", "ICL",
"Chull_fac", "BIC_G_fac", "BIC_N_fac", "AIC_fac", "AIC3_fac", "ICL_fac")
load("design.Rdata")
load("~/GitHub/ModelSelection_Simulation/Results/FinalResCorrectModel.Rdata")
####################################################################################################
############################ TABLES - CLUSTER AND PARAMETER RECOVERY ###############################
####################################################################################################
# Check mean results per simulation factor
# Create a function for this
count_results <- function(data, by, type = "count"){
# Extract necessary columns
reduced <- data %>% dplyr::select(Chull:ICL_fac)
#Initialize objects to store
counted        <- vector(mode = "list", length = ncol(reduced))
names(counted) <- colnames(reduced)
final <- c()
# browser()
# Count per column
for(i in 1:ncol(reduced)){
if(length(by) == 1 && by == "total"){
counted[[i]] <- data %>% count(get(colnames(reduced)[i]), .drop = F) %>% filter(!is.na(`get(colnames(reduced)[i])`)) # Count and remove NA
if(type == "relative"){
counted[[i]][, ncol(counted[[i]])] <- round(counted[[i]][, ncol(counted[[i]]), drop = F]/sum(counted[[i]][, ncol(counted[[i]]), drop = F]), 3)
}
# browser()
colnames(counted[[i]]) <- c("result", colnames(reduced)[i]) # change colnames
ifelse(test = i == 1, yes = final <- counted[[i]][, 1, drop = F], no = final <- final) # for the first iteration, keep the group variable and results column
final <- cbind(final, counted[[i]][, ncol(counted[[i]]), drop = F]) # Add the results for each measure
} else {
# browser()
counted[[i]] <- data %>% group_by(across(all_of(by))) %>% count(get(colnames(reduced)[i]), .drop = F) %>% filter(!is.na(`get(colnames(reduced)[i])`)) # count per measure
# browser()
if(type == "relative"){
counted[[i]][, ncol(counted[[i]])] <- round(counted[[i]][, ncol(counted[[i]])]/sum(counted[[i]][1:3, ncol(counted[[i]])]), 3)
}
colnames(counted[[i]]) <- c(by, "result", colnames(reduced)[i]) # change colnames
ifelse(test = i == 1, yes = final <- counted[[i]][, c(seq_len(length(by)), (length(by) + 1))], no = final <- final) # for the first iteration, keep the group variable and results column
final <- cbind(final, counted[[i]][, ncol(counted[[i]]), drop = F]) # Add the results for each measure
}
}
return(final)
}
# Pre-check to know if there are NAs
colSums(apply(Results_final, 2, is.na))
# Main effects
count_results(data = Results_final, by = "total", type = "relative")
View(Results_final)
View(Results_final)
Results_final <- Results_final %>% select(Condition:entropyR2, Chull_fac:ICL_fac)
sub(pattern = "_fac", replacement = "", x = colnames(Results_final))
colnames(Results_final) <- sub(pattern = "_fac", replacement = "", x = colnames(Results_final))
####################################################################################################
############################ TABLES - CLUSTER AND PARAMETER RECOVERY ###############################
####################################################################################################
# Check mean results per simulation factor
# Create a function for this
count_results <- function(data, by, type = "count"){
# Extract necessary columns
reduced <- data %>% dplyr::select(Chull:ICL_fac)
#Initialize objects to store
counted        <- vector(mode = "list", length = ncol(reduced))
names(counted) <- colnames(reduced)
final <- c()
# browser()
# Count per column
for(i in 1:ncol(reduced)){
if(length(by) == 1 && by == "total"){
counted[[i]] <- data %>% count(get(colnames(reduced)[i]), .drop = F) %>% filter(!is.na(`get(colnames(reduced)[i])`)) # Count and remove NA
if(type == "relative"){
counted[[i]][, ncol(counted[[i]])] <- round(counted[[i]][, ncol(counted[[i]]), drop = F]/sum(counted[[i]][, ncol(counted[[i]]), drop = F]), 3)
}
# browser()
colnames(counted[[i]]) <- c("result", colnames(reduced)[i]) # change colnames
ifelse(test = i == 1, yes = final <- counted[[i]][, 1, drop = F], no = final <- final) # for the first iteration, keep the group variable and results column
final <- cbind(final, counted[[i]][, ncol(counted[[i]]), drop = F]) # Add the results for each measure
} else {
# browser()
counted[[i]] <- data %>% group_by(across(all_of(by))) %>% count(get(colnames(reduced)[i]), .drop = F) %>% filter(!is.na(`get(colnames(reduced)[i])`)) # count per measure
# browser()
if(type == "relative"){
counted[[i]][, ncol(counted[[i]])] <- round(counted[[i]][, ncol(counted[[i]])]/sum(counted[[i]][1:3, ncol(counted[[i]])]), 3)
}
colnames(counted[[i]]) <- c(by, "result", colnames(reduced)[i]) # change colnames
ifelse(test = i == 1, yes = final <- counted[[i]][, c(seq_len(length(by)), (length(by) + 1))], no = final <- final) # for the first iteration, keep the group variable and results column
final <- cbind(final, counted[[i]][, ncol(counted[[i]]), drop = F]) # Add the results for each measure
}
}
return(final)
}
# Pre-check to know if there are NAs
colSums(apply(Results_final, 2, is.na))
# Main effects
count_results(data = Results_final, by = "total", type = "relative")
####################################################################################################
############################ TABLES - CLUSTER AND PARAMETER RECOVERY ###############################
####################################################################################################
# Check mean results per simulation factor
# Create a function for this
count_results <- function(data, by, type = "count"){
# Extract necessary columns
reduced <- data %>% dplyr::select(Chull:ICL)
#Initialize objects to store
counted        <- vector(mode = "list", length = ncol(reduced))
names(counted) <- colnames(reduced)
final <- c()
# browser()
# Count per column
for(i in 1:ncol(reduced)){
if(length(by) == 1 && by == "total"){
counted[[i]] <- data %>% count(get(colnames(reduced)[i]), .drop = F) %>% filter(!is.na(`get(colnames(reduced)[i])`)) # Count and remove NA
if(type == "relative"){
counted[[i]][, ncol(counted[[i]])] <- round(counted[[i]][, ncol(counted[[i]]), drop = F]/sum(counted[[i]][, ncol(counted[[i]]), drop = F]), 3)
}
# browser()
colnames(counted[[i]]) <- c("result", colnames(reduced)[i]) # change colnames
ifelse(test = i == 1, yes = final <- counted[[i]][, 1, drop = F], no = final <- final) # for the first iteration, keep the group variable and results column
final <- cbind(final, counted[[i]][, ncol(counted[[i]]), drop = F]) # Add the results for each measure
} else {
# browser()
counted[[i]] <- data %>% group_by(across(all_of(by))) %>% count(get(colnames(reduced)[i]), .drop = F) %>% filter(!is.na(`get(colnames(reduced)[i])`)) # count per measure
# browser()
if(type == "relative"){
counted[[i]][, ncol(counted[[i]])] <- round(counted[[i]][, ncol(counted[[i]])]/sum(counted[[i]][1:3, ncol(counted[[i]])]), 3)
}
colnames(counted[[i]]) <- c(by, "result", colnames(reduced)[i]) # change colnames
ifelse(test = i == 1, yes = final <- counted[[i]][, c(seq_len(length(by)), (length(by) + 1))], no = final <- final) # for the first iteration, keep the group variable and results column
final <- cbind(final, counted[[i]][, ncol(counted[[i]]), drop = F]) # Add the results for each measure
}
}
return(final)
}
# Pre-check to know if there are NAs
colSums(apply(Results_final, 2, is.na))
# Main effects
count_results(data = Results_final, by = "total", type = "relative")
K_res   <- count_results(data = Results_final, by = c("nclus"), type = "relative")
N_res   <- count_results(data = Results_final, by = c("N_g"), type = "relative")
G_res   <- count_results(data = Results_final, by = c("ngroups"), type = "relative")
B_res   <- count_results(data = Results_final, by = c("coeff"), type = "relative")
Bal_res <- count_results(data = Results_final, by = c("balance"), type = "relative")
sd_res  <- count_results(data = Results_final, by = c("sd"), type = "relative")
count_results(data = Results_final, by = c("sd", "N_g"), type = "relative")
mean(Results_final$entropyR2)
# HEATMAP
a <- count_results(data = Results_final, by = c("sd", "nclus"), type = "relative") %>% filter(result == "Correct")
a1 <- a %>% dplyr::select(sd, nclus, Chull:ICL) %>% pivot_longer(cols = Chull:ICL, names_to = "Measure", values_to = "Proportion")
a1$Measure <- factor(a1$Measure, levels = c("BIC_N", "ICL", "BIC_G", "AIC3", "AIC", "Chull"))
plot <- ggplot(data = a1, aes(x = sd, y = Measure)) + facet_grid(~nclus) +
geom_tile(aes(fill = Proportion)) + geom_text(aes(label = Proportion), size = 3.2) +
scale_fill_gradient(low = "yellow", high = "green4") +
scale_x_continuous(sec.axis = sec_axis(~ . , name = "Number of clusters", breaks = NULL, labels = NULL)) +
labs(x = expression("Within-cluster differences (" * sigma[beta] * ")"),  # Combines text with Greek letter, no space
y = expression("Model Selection measure")) +
scale_y_discrete(labels = c("Chull" = "CHull",
"AIC" = "AIC",
"AIC3" = expression(AIC[3]),
"BIC_G" = expression(BIC[G]),
"ICL" = "ICL",
"BIC_N" = expression(BIC[N])))
plot
K_res   <- count_results(data = Results_final, by = c("nclus"), type = "relative")   %>% select(nclus:ICL)
N_res   <- count_results(data = Results_final, by = c("N_g"), type = "relative")     %>% select(N_g:ICL)
G_res   <- count_results(data = Results_final, by = c("ngroups"), type = "relative") %>% select(ngroups:ICL)
B_res   <- count_results(data = Results_final, by = c("coeff"), type = "relative")   %>% select(coeff:ICL)
Bal_res <- count_results(data = Results_final, by = c("balance"), type = "relative") %>% select(balance:ICL)
sd_res  <- count_results(data = Results_final, by = c("sd"), type = "relative")      %>% select(sd:ICL)
to_res  <- count_results(data = Results_final, by = "total", type = "relative")      %>% select(result:ICL)
K_res   <- K_res %>%
pivot_longer(cols = -c(nclus, result), names_to = "metric", values_to = "value") %>%
pivot_wider(names_from = nclus, values_from = value, names_prefix = "nclus") %>%
relocate(metric) %>% arrange(metric)
N_res   <- N_res %>%
pivot_longer(cols = -c(N_g, result), names_to = "metric", values_to = "value") %>%
pivot_wider(names_from = N_g, values_from = value, names_prefix = "N_g") %>%
relocate(metric) %>% arrange(metric) %>% select(contains("N_g"))
G_res   <- G_res %>%
pivot_longer(cols = -c(ngroups, result), names_to = "metric", values_to = "value") %>%
pivot_wider(names_from = ngroups, values_from = value, names_prefix = "ngroups") %>%
relocate(metric) %>% arrange(metric) %>% select(contains("ngroups"))
B_res   <- B_res %>%
pivot_longer(cols = -c(coeff, result), names_to = "metric", values_to = "value") %>%
pivot_wider(names_from = coeff, values_from = value, names_prefix = "coeff") %>%
relocate(metric) %>% arrange(metric) %>% select(contains("coeff"))
Bal_res <- Bal_res %>%
pivot_longer(cols = -c(balance, result), names_to = "metric", values_to = "value") %>%
pivot_wider(names_from = balance, values_from = value, names_prefix = "balance") %>%
relocate(metric) %>% arrange(metric) %>% select(contains("balance"))
sd_res  <- sd_res %>%
pivot_longer(cols = -c(sd, result), names_to = "metric", values_to = "value") %>%
pivot_wider(names_from = sd, values_from = value, names_prefix = "sd") %>%
relocate(metric) %>% arrange(metric) %>% select(contains("sd"))
to_res  <- to_res %>%
pivot_longer(cols = -c(result), names_to = "metric", values_to = "value") %>%
relocate(metric) %>% arrange(metric) %>% select(value)
final <- cbind(K_res, N_res, G_res, B_res, Bal_res, sd_res, to_res)
# Add totals per column
total_col <- cbind("total", final %>% group_by(result) %>% summarise(across(where(is.numeric), mean, na.rm = TRUE)))
colnames(total_col)[1] <- "metric"; colnames(total_col)[ncol(total_col)] <- "value"
final <- rbind(final, total_col)
print(xtable(final), include.rownames=FALSE)
sd_res
View(final)
