# compute cov(Z)
Zc <- t(t(Z) - colMeans(Z))
Gamma <- crossprod(Zc)/N
Gamma
}
compute_gamma(HolzingerSwineford1939[,7:8]) # P = 2
Yc[, idx1, drop = FALSE]
cbind(Y, Yc[, idx1, drop = FALSE] * Yc[, idx2, drop = FALSE])
Y %x% Y
Y %x% Yc
###################################################
### code chunk number 70: lavaan_num_eam2018.Rtex:1801-1820
###################################################
compute_gamma <- function(Y) {
N <- nrow(Y)
P <- ncol(Y)
# center
Yc <- t(t(Y) - colMeans(Y))
# compute crossproduct, row-wise
idx1 <- lavaan:::lav_matrix_vech_col_idx(P)
idx2 <- lavaan:::lav_matrix_vech_row_idx(P)
Z <- cbind(Y, Yc[, idx1, drop = FALSE] * Yc[, idx2, drop = FALSE])
# compute cov(Z)
Zc <- t(t(Z) - colMeans(Z))
Gamma <- crossprod(Zc)/N
Gamma
}
compute_gamma(HolzingerSwineford1939[,7:8]) # P = 2
###################################################
### code chunk number 71: lavaan_num_eam2018.Rtex:1846-1848
###################################################
set.seed(1234)
N <- 200; P <- 3
###################################################
### code chunk number 72: lavaan_num_eam2018.Rtex:1850-1856
###################################################
Mu <- c(10,20,30)
Sigma <- matrix(c(8,4,2, 4,6,3, 2,3,4), 3, 3)
# generate random data
library(MASS)
Y <- MASS::mvrnorm(n = N, mu = Mu, Sigma = Sigma)
colnames(Y) <- c("y1","y2","y3")
###################################################
### code chunk number 73: lavaan_num_eam2018.Rtex:1858-1863
###################################################
# compute sample statistics
ybar <- colMeans(Y)
ybar
S <- cov(Y) * (N-1)/N
S
###################################################
### code chunk number 74: lavaan_num_eam2018.Rtex:1871-1875
###################################################
S.inv <- solve(S)
D <- lav_matrix_duplication(ncol(S))
library(dplyr)
library(lavaan)
# Center data just to ignore mean structure
Data <- HolzingerSwineford1939 %>% dplyr::select(x1:x6) %>% scale(x = ., center = T, scale = F) %>% as.data.frame()
Data$group <- HolzingerSwineford1939$school
# Fit sam for reference
HS.model <- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
visual ~ textual
'
fit.sam <- sam(HS.model, data = Data,
mm.list = list(c("visual", "textual")), sam.method = "global",
information = "observed", group = "group"
)
summary(fit.sam)
# Fit SAM manually -----------------------------------------------------------------------------------------------------
# Fit a fake SEM
HS.model <- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
visual ~ textual
'
fit.fake     <- sem(HS.model, data = Data, information = "observed", meanstructure = F, do.fit = F, group = "group")
PT.fake      <- parTable(fit.fake)
PT.fake$se   <- NULL
PT.fake$est  <- NULL
PT.fake$free <- 0
summary(fit.fake)
# Fit a global SAM ----------------------------------
# MM
HS.MM <- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
'
fit.MM <- cfa(HS.MM, data = Data, information = "observed", meanstructure = F, group = "group")
# Get parameter table of step 1
PT.MM <- partable(fit.MM)
# Extract all parameters
est_S1 <- lavInspect(object = fit.MM, what = "est")
cov_S1 <- lapply(est_S1, "[[", "psi")
n_g <- lavInspect(fit.MM, what = "nobs")
p <- Data %>% dplyr::select(x1:x6) %>% ncol()
q <- length(lavNames(fit.MM, type = "lv"))
# Remove the structural parameters of the parameter table
idx.str   <- which(PT.MM$rhs %in% lavNames(fit.MM, type = "lv"))
PT.MM     <- PT.MM[-idx.str, ]
# Fill out MM parameters in the fake table
# First make a full parameter column
PT.MM$par   <- paste0(PT.MM$lhs, PT.MM$op, PT.MM$rhs, ".g", PT.MM$group)
PT.fake$par <- paste0(PT.fake$lhs, PT.fake$op, PT.fake$rhs, ".g", PT.fake$group)
idx.par <- match(PT.MM$par, PT.fake$par) # indices of parameters from PT.MM on PT.fake
PT.fake$ustart[idx.par] <- PT.MM$est
PT.fake$free[is.na(PT.fake$ustart)] <- 1:sum(is.na(PT.fake$ustart))
PT.fake$par <- NULL
# SM
fit.global <- sem(model         = PT.fake,
data          = Data,
information   = "observed",
meanstructure = F,
group         = "group")
summary(fit.global) # Pointwise estimation is correct. SE is underestimated (as expected).
fit.sem <- sem(HS.model, data = Data,
information = "observed", group = "group"
)
# Fit SAM manually -----------------------------------------------------------------------------------------------------
# Center data to remove mean structure (it simplies stuff)
Data <- HolzingerSwineford1939 %>% dplyr::select(x1:x6) %>% scale(x = ., center = T, scale = F)
# MM
HS.MM <- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
'
fit.MM <- cfa(HS.MM, data = Data, information = "observed")
# Extract all parameters
est_S1 <- lavInspect(object = fit.MM, what = "est")
# lambda_S1 <- est_S1$lambda
# theta_S1  <- est_S1$theta
cov_S1    <- est_S1$psi
# SM
HS.SM <- '
visual ~ textual
'
fit.SM <- sem(HS.SM, sample.cov = cov_S1, sample.nobs = 301, information = "observed")
summary(fit.SM) # Pointwise estimation is correct. SE is underestimated (as expected).
# Extract structural parameters
est_S2 <- lavInspect(object = fit.SM, what = "est")
cov_S2  <- est_S2$psi
# (2) Use numDeriv to replicate all parts of the I matrix --------------------------------------------------------------
p <- ncol(Data)
q <- length(lavNames(fit.MM, type = "lv"))
# First, replicate Hessian of the parameters in Step 1
obj.S1 <- function(x){
lambda <- matrix(data = 0, nrow = p, ncol = q)
lambda[1, 1] <- 1; lambda[4, 2] <- 1
lambda[2:3, 1] <- x[1:2]
lambda[5:6, 2] <- x[3:4]
theta <- matrix(data = 0, nrow = p, ncol = p)
diag(theta) <- x[5:10]
psi <- matrix(data = 0, nrow = q, ncol = q)
psi[1, 1] <- x[11]
psi[2, 2] <- x[12]
psi[2, 1] <- psi[1, 2] <- x[13]
Sigma_new <- lambda %*% psi %*% t(lambda) + theta
LL <- lavaan:::lav_mvnorm_loglik_samplestats(
sample.mean = numeric(6),
sample.nobs = 301, # Use original sample size to get the correct loglikelihood
# sample.nobs = N_gks[g, k],
sample.cov  = (cov(Data) * 300) / 301, # Factor covariance matrix from step 1
Mu          = numeric(2),
Sigma       = Sigma_new # Factor covariance matrix from step 2
)
return(LL)
}
S1par <- coef(fit.MM, type = "free")
H_1 <- numDeriv::hessian(func = obj.S1, x = S1par)
# Second, replicate the Hessian of the parameters of Step 2 (NOT NECESSARY)
obj.S2 <- function(x){
beta <- matrix(data = 0, nrow = q, ncol = q)
beta[1, 2] <- x[1]
psi <- matrix(data = 0, nrow = q, ncol = q)
psi[1, 1] <- x[2]
psi[2, 2] <- x[3]
Sigma_new <- solve(I - beta) %*% psi %*% t(solve(I - beta))
LL <- lavaan:::lav_mvnorm_loglik_samplestats(
sample.mean = numeric(2),
sample.nobs = 301,
sample.cov  = (cov_S1 * 300) / 301,
Mu          = numeric(2),
Sigma       = Sigma_new
)
return(-1 * LL)
}
I <- diag(q)
S2par <- coef(fit.SM, type = "free")
H_2 <- numDeriv::hessian(func = obj.S2, x = S2par)
S2par
# SM
HS.SM <- '
visual ~ textual
textual ~~ textual
'
fit.SM <- sem(HS.SM, sample.cov = cov_S1, sample.nobs = 301, information = "observed")
I <- diag(q)
S2par <- coef(fit.SM, type = "free")
H_2 <- numDeriv::hessian(func = obj.S2, x = S2par)
H_2
# Third, replicate C. Is it possible with numDeriv?
obj.comb <- function(x){
lambda <- matrix(data = 0, nrow = p, ncol = q)
lambda[1, 1] <- 1; lambda[4, 2] <- 1
lambda[2:3, 1] <- x[1:2]
lambda[5:6, 2] <- x[3:4]
theta <- matrix(data = 0, nrow = p, ncol = p)
diag(theta) <- x[5:10]
beta <- matrix(data = 0, nrow = q, ncol = q)
beta[1, 2] <- x[11]
psi <- matrix(data = 0, nrow = q, ncol = q)
psi[1, 1] <- x[12]
psi[2, 2] <- x[13]
Sigma_new <- lambda %*% solve(I - beta) %*% psi %*% t(solve(I - beta)) %*% t(lambda) + theta
LL <- lavaan:::lav_mvnorm_loglik_samplestats(
sample.mean = numeric(6),
sample.nobs = 301,
sample.cov  = (cov(Data) * 300) / 301,
Mu          = numeric(2),
Sigma       = Sigma_new
)
return(LL)
}
HESS <- numDeriv::hessian(func = obj.comb, x = c(S1par[1:10], S2par)) # S2 parameters are different for some reason
I_22
# Extract the individual parts of the matrix
I_11 <- -HESS[1:10, 1:10]
I_22 <- -HESS[11:13, 11:13]
I_21 <- -HESS[11:13, 1:10]
I_22
H2
H_2
1 == 1
# 08-08-2023
# Reproducing the covariance matrix of the parameters in lavaan's SAM (two-step estimation)
library(dplyr)
library(lavaan)
# MG-SEM model for reference -------------------------------------------------------------------------------------------
# Center data just to ignore mean structure
Data <- HolzingerSwineford1939 %>% dplyr::select(x1:x6) %>% scale(x = ., center = T, scale = F) %>% as.data.frame()
Data$group <- HolzingerSwineford1939$school
# Fit a "configural" MG-SEM --------------------------------------------------------------------------------------------
HS.model <- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
visual ~ textual
'
# Fit a "metric" MG-SEM ------------------------------------------------------------------------------------------------
fit.sem.metric <- sem(HS.model, data = Data, information = "observed", group = "group",
meanstructure = F, group.equal = "loadings", ceq.simple = T)
View(partable(fit.sem.metric))
# Fit a "metric" MG-SEM ------------------------------------------------------------------------------------------------
fit.sem.metric <- sem(HS.model, data = Data, information = "observed", group = "group",
meanstructure = F, group.equal = "loadings", ceq.simple = F)
View(partable(fit.sem.metric))
library(lavaan)
library(dplyr)
# Center data just to ignore mean structure
Data <- HolzingerSwineford1939 %>% dplyr::select(x1:x6) %>% scale(x = ., center = T, scale = F) %>% as.data.frame()
Data$group <- HolzingerSwineford1939$school
# Fit SAM manually -----------------------------------------------------------------------------------------------------
# Fit a fake SEM
HS.model <- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
visual ~ textual
'
fit.fake     <- sem(HS.model, data = Data, information = "observed", meanstructure = F, do.fit = F, group = "group")
PT.fake      <- parTable(fit.fake)
PT.fake$se   <- NULL
PT.fake$est  <- NULL
PT.fake$free <- 0
summary(fit.fake)
# Fit a global SAM ----------------------------------
# MM
HS.MM <- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
'
fit.MM <- cfa(HS.MM, data = Data, information = "observed", meanstructure = F, group = "group")
# Get parameter table of step 1
PT.MM <- partable(fit.MM)
# Extract all parameters
est_S1 <- lavInspect(object = fit.MM, what = "est")
cov_S1 <- lapply(est_S1, "[[", "psi")
n_g <- lavInspect(fit.MM, what = "nobs")
p <- Data %>% dplyr::select(x1:x6) %>% ncol()
q <- length(lavNames(fit.MM, type = "lv"))
# Remove the structural parameters of the parameter table
idx.str   <- which(PT.MM$rhs %in% lavNames(fit.MM, type = "lv"))
PT.MM     <- PT.MM[-idx.str, ]
# Fill out MM parameters in the fake table
# First make a full parameter column
PT.MM$par   <- paste0(PT.MM$lhs, PT.MM$op, PT.MM$rhs, ".g", PT.MM$group)
PT.fake$par <- paste0(PT.fake$lhs, PT.fake$op, PT.fake$rhs, ".g", PT.fake$group)
idx.par <- match(PT.MM$par, PT.fake$par) # indices of parameters from PT.MM on PT.fake
PT.fake$ustart[idx.par] <- PT.MM$est
PT.fake$free[is.na(PT.fake$ustart)] <- 1:sum(is.na(PT.fake$ustart))
PT.fake$par <- NULL
PT.fake
PT.MM
fit.fake     <- sem(HS.model, data = Data, information = "observed", meanstructure = F, do.fit = T, group = "group")
partable(fit.fake)
fit.fake     <- sem(HS.model, data = Data, information = "observed", meanstructure = F, do.fit = F, group = "group")
PT.fake      <- parTable(fit.fake)
PT.fake$se   <- NULL
PT.fake$est  <- NULL
PT.fake$free <- 0
summary(fit.fake)
PT.fake
# SM
fit.global <- sem(model         = PT.fake,
data          = Data,
information   = "observed",
meanstructure = F,
group         = "group")
summary(fit.global) # Pointwise estimation is correct. SE is underestimated (as expected).
# SM
fit.global <- sem(model         = PT.fake,
data          = Data,
information   = "observed",
meanstructure = F,
group         = "group")
HS.model <- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
visual ~ textual
'
fit.fake     <- sem(HS.model, data = Data, information = "observed", meanstructure = F, do.fit = F, group = "group")
PT.fake      <- parTable(fit.fake)
PT.fake$se   <- NULL
PT.fake$est  <- NULL
PT.fake$free <- 0
summary(fit.fake)
# Fit a global SAM ----------------------------------
# MM
HS.MM <- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
'
fit.MM <- cfa(HS.MM, data = Data, information = "observed", meanstructure = F, group = "group")
# Get parameter table of step 1
PT.MM <- partable(fit.MM)
# Extract all parameters
est_S1 <- lavInspect(object = fit.MM, what = "est")
cov_S1 <- lapply(est_S1, "[[", "psi")
n_g <- lavInspect(fit.MM, what = "nobs")
p <- Data %>% dplyr::select(x1:x6) %>% ncol()
q <- length(lavNames(fit.MM, type = "lv"))
# Remove the structural parameters of the parameter table
idx.str   <- which(PT.MM$rhs %in% lavNames(fit.MM, type = "lv"))
PT.MM     <- PT.MM[-idx.str, ]
# Fill out MM parameters in the fake table
# First make a full parameter column
PT.MM$par   <- paste0(PT.MM$lhs, PT.MM$op, PT.MM$rhs, ".g", PT.MM$group)
PT.fake$par <- paste0(PT.fake$lhs, PT.fake$op, PT.fake$rhs, ".g", PT.fake$group)
idx.par <- match(PT.MM$par, PT.fake$par) # indices of parameters from PT.MM on PT.fake
PT.fake$ustart[idx.par] <- PT.MM$est
PT.fake$free[is.na(PT.fake$ustart)] <- 1:sum(is.na(PT.fake$ustart))
PT.fake$par <- NULL
# SM
fit.global <- sem(model         = PT.fake,
data          = Data,
information   = "observed",
meanstructure = F,
group         = "group")
# Center data just to ignore mean structure
Data <- HolzingerSwineford1939 %>% dplyr::select(x1:x6) %>% scale(x = ., center = T, scale = F) %>% as.data.frame()
Data$group <- HolzingerSwineford1939$school
HS.MM <- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
'
fit.MM <- cfa(HS.MM, data = Data, information = "observed", meanstructure = F, group = "group")
# Get parameter table of step 1
PT.MM <- partable(fit.MM)
# Extract all parameters
est_S1 <- lavInspect(object = fit.MM, what = "est")
cov_S1 <- lapply(est_S1, "[[", "psi")
n_g <- lavInspect(fit.MM, what = "nobs")
p <- Data %>% dplyr::select(x1:x6) %>% ncol()
q <- length(lavNames(fit.MM, type = "lv"))
# Remove the structural parameters of the parameter table
idx.str   <- which(PT.MM$rhs %in% lavNames(fit.MM, type = "lv"))
PT.MM     <- PT.MM[-idx.str, ]
# Fill out MM parameters in the fake table
# First make a full parameter column
PT.MM$par   <- paste0(PT.MM$lhs, PT.MM$op, PT.MM$rhs, ".g", PT.MM$group)
PT.fake$par <- paste0(PT.fake$lhs, PT.fake$op, PT.fake$rhs, ".g", PT.fake$group)
idx.par <- match(PT.MM$par, PT.fake$par) # indices of parameters from PT.MM on PT.fake
PT.fake$ustart[idx.par] <- PT.MM$est
PT.fake$free[is.na(PT.fake$ustart)] <- 1:sum(is.na(PT.fake$ustart))
PT.fake$par <- NULL
# SM
fit.global <- sem(model         = PT.fake,
data          = Data,
information   = "observed",
meanstructure = F,
group         = "group")
# Fit a global SAM ----------------------------------
# MM
HS.MM <- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
'
fit.MM <- cfa(HS.MM, data = Data, information = "observed", meanstructure = F, group = "group")
# Get parameter table of step 1
PT.MM <- partable(fit.MM)
# Extract all parameters
est_S1 <- lavInspect(object = fit.MM, what = "est")
cov_S1 <- lapply(est_S1, "[[", "psi")
n_g <- lavInspect(fit.MM, what = "nobs")
p <- Data %>% dplyr::select(x1:x6) %>% ncol()
q <- length(lavNames(fit.MM, type = "lv"))
# Remove the structural parameters of the parameter table
idx.str   <- which(PT.MM$rhs %in% lavNames(fit.MM, type = "lv"))
PT.MM     <- PT.MM[-idx.str, ]
# Fill out MM parameters in the fake table
# First make a full parameter column
PT.MM$par   <- paste0(PT.MM$lhs, PT.MM$op, PT.MM$rhs, ".g", PT.MM$group)
PT.fake$par <- paste0(PT.fake$lhs, PT.fake$op, PT.fake$rhs, ".g", PT.fake$group)
fit.fake     <- sem(HS.model, data = Data, information = "observed", meanstructure = F, do.fit = F, group = "group")
PT.fake      <- parTable(fit.fake)
PT.fake$se   <- NULL
PT.fake$est  <- NULL
PT.fake$free <- 0
PT.fake$par <- paste0(PT.fake$lhs, PT.fake$op, PT.fake$rhs, ".g", PT.fake$group)
idx.par <- match(PT.MM$par, PT.fake$par) # indices of parameters from PT.MM on PT.fake
PT.fake$ustart[idx.par] <- PT.MM$est
PT.fake$free[is.na(PT.fake$ustart)] <- 1:sum(is.na(PT.fake$ustart))
PT.fake$par <- NULL
# SM
fit.global <- sem(model         = PT.fake,
data          = Data,
information   = "observed",
meanstructure = F,
group         = "group")
summary(fit.global) # Pointwise estimation is correct. SE is underestimated (as expected).
PT.fake
PT.MM$est
PT.fake$start <- NULL
# SM
fit.global <- sem(model         = PT.fake,
data          = Data,
information   = "observed",
meanstructure = F,
group         = "group")
summary(fit.global) # Pointwise estimation is correct. SE is underestimated (as expected).
partable(fit.global)
library(lavaan)
library(qwraps2)
library(fpp3)
library(dplyr)
library(xtable)
library(ggpubr)
library(ggplot2)
library(ggthemes)
# Set wd
setwd("~/GitHub/ModelSelection_Simulation/Results")
# Load empty final results matrix
load("FinalResults.Rdata")
colnames(Results_final)[1:8] <- c("Chull Scree", "BIC_G", "BIC_N", "AIC", "Chull Scree_fac",
"BIC_G_fac", "BIC_N_fac", "AIC_fac")
load("design.Rdata")
# Merge datasets
design$Condition <- as.numeric(rownames(design))
Results_final <- merge(x = design, y = Results_final, by = "Condition")
col_order <- c("Condition", "Replication", "nclus", "ngroups", "coeff", "N_g",
"balance", "reliability", "NonInvSize", "ResRange", "NonInvItems", "NonInvG",
"NonInvType", "Chull Scree", "BIC_G", "BIC_N", "AIC", "Chull Scree_fac",
"BIC_G_fac", "BIC_N_fac", "AIC_fac")
Results_final <- Results_final[, col_order]
rm(col_order)
# Fill in the matrix with all results
ncond <- unique(Results_final$Condition) # How many conditions?
K <- length(unique(Results_final$Replication)) # How many replications?
for (i in ncond) {
test <- NA
test <- try(load(paste0("ResultRow", i, ".Rdata")))
if(!c(class(test) == "try-error")){
Results_final[(K*(i-1)+1):(i*K), 14:21] <- ResultsRow
}
}
# Turn NAs from Chull into FALSE input (Chull was not able to select any model)
# apply(X = apply(X = Results_final, MARGIN = 2, FUN = is.na), MARGIN = 2, FUN = sum)
Results_final$`Chull Scree` <- ifelse(test = is.na(Results_final$`Chull Scree`), yes = FALSE, no = Results_final$`Chull Scree`)
####################################################################################################
############################ TABLES - CLUSTER AND PARAMETER RECOVERY ###############################
####################################################################################################
Results_final %>% dplyr::select(`Chull Scree`:AIC_fac) %>% apply(MARGIN = 2, FUN = table)
####################################################################################################
############################ TABLES - CLUSTER AND PARAMETER RECOVERY ###############################
####################################################################################################
Results_final %>% dplyr::select(`Chull Scree`:AIC_fac) %>% apply(MARGIN = 2, FUN = prop.table)
####################################################################################################
############################ TABLES - CLUSTER AND PARAMETER RECOVERY ###############################
####################################################################################################
Results_final %>% dplyr::select(`Chull Scree`:AIC_fac) %>% apply(MARGIN = 2, FUN = table)
####################################################################################################
############################ TABLES - CLUSTER AND PARAMETER RECOVERY ###############################
####################################################################################################
Results_final %>% dplyr::select(`Chull Scree`:AIC_fac) %>% apply(MARGIN = 2, FUN = function(x) table(x)/nrow(x))
####################################################################################################
############################ TABLES - CLUSTER AND PARAMETER RECOVERY ###############################
####################################################################################################
Results_final %>% dplyr::select(`Chull Scree`:AIC_fac) %>% apply(MARGIN = 2, FUN = table)/540
####################################################################################################
############################ TABLES - CLUSTER AND PARAMETER RECOVERY ###############################
####################################################################################################
Results_final %>% dplyr::select(`Chull Scree`:AIC_fac) %>% apply(MARGIN = 2, FUN = table)/540
